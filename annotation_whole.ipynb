{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d8cbe40-4b8a-4daa-9482-4f3a1be268ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "import napari\n",
    "import pandas as pd\n",
    "import zarr\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from cellpose import models\n",
    "import tiffile as tf\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4739b454-3f5f-45c9-8bde-fa47894fd565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "import pickle \n",
    "print(pickle.format_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f820e5d1-a6ab-4900-a97e-967646eceded",
   "metadata": {},
   "source": [
    "### Get Annotation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3b40fd2-9e1b-4561-a547-677757e2370b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1294945/3534847048.py:19: FutureWarning: The N5Store is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "  fix_zarr = [zarr.open(store=zarr.N5Store(fix_n5_path[0]), mode='r'), zarr.open(store=zarr.N5Store(fix_n5_path[1]), mode='r')]\n"
     ]
    }
   ],
   "source": [
    "##### change path\n",
    "# first path need to be first brain,second path need to be another brain\n",
    "fix_n5_path = ['/mnt/aperto/fused/fused.n5','/mnt/aperto/fused/fused.n5']\n",
    "# save path\n",
    "#create the directory if it does not exist\n",
    "##### change path\n",
    "# you need to change to the folder you want\n",
    "directory = './tatz_annotation/'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    print(\"Directory created:\", directory)\n",
    "##### change path\n",
    "save_path = directory\n",
    "##### change path\n",
    "#you need to change to the folder you want metadata path\n",
    "meta_path = './tatz_annotation/tatz_annotation.pkl'\n",
    "\n",
    "# create Zarr file object\n",
    "fix_zarr = [zarr.open(store=zarr.N5Store(fix_n5_path[0]), mode='r'), zarr.open(store=zarr.N5Store(fix_n5_path[1]), mode='r')]\n",
    "# if you use ngff ome.zarr\n",
    "# mov_zarr_path = '/mnt/ampa02_data01/tmurakami/240417_whole_4color_1st_M037-3pb/registration/round02.zarr'\n",
    "# mov_zarr = zarr.open(mov_zarr_path, mode='r')\n",
    "\n",
    "n5_setups = list(fix_zarr[0].keys())\n",
    "\n",
    "voxel_size = (2.0,1.3,1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a62f4fe5-a1db-46b2-b4b0-0e5b635b3f5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make metadata file if it does not exist.\n",
    "if not os.path.exists(meta_path):\n",
    "    df = pd.DataFrame(columns=['ID', 'integer_ID', 'instance_counts', 'corner', 'source', 'ref_channel', 'channel', 'crop_size', 'isHard', 'plane_position'])\n",
    "else:\n",
    "    df = pd.read_pickle(meta_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f33f7d2-82b1-48b4-aef2-7b9998f913df",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolusion_0_shape = fix_zarr[0][n5_setups[1]]['timepoint0']['s0'].shape\n",
    "resolusion_2_shape = fix_zarr[0][n5_setups[3]]['timepoint0']['s2'].shape\n",
    "scale_size = []\n",
    "for i in range(len(resolusion_0_shape)):\n",
    "    scale_size.append(resolusion_2_shape[i]/resolusion_0_shape[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4e51507-0a99-4f5d-b8e5-03b3ba5f07bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your parameters here\n",
    "reference_chan = 3 # Integer or None\n",
    "segment_chan = 4\n",
    "\n",
    "# [100,256,256] crop size and FoV [100,768,768] are recommended for the 2D annotation\n",
    "crop_size = [100,256,256]\n",
    "FoV = [100,768, 768]\n",
    "FoV1 = [1, 2137, 1603]\n",
    "# set True for 2D annotation and set False for 3D annotation\n",
    "select_plane = True\n",
    "\n",
    "# processing of parameters\n",
    "if not all([(j-i)>=0 for i,j in zip(crop_size, FoV)]):\n",
    "    raise ValueError('FoV should be larger than crop_size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5662909-c2f1-47e0-9fcd-40f74b3c091b",
   "metadata": {},
   "source": [
    "#### load original images need to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d2c85b8-422c-4d16-9a9b-053b483488e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all files in the directory ending with '_img.tif', and '_mask.tif' \n",
    "##### change path\n",
    "#you need to change this path to your image and mask file path\n",
    "img_dir = '/mnt/aperto/yin/cellpose_training/data/train/' \n",
    "img_files = sorted(glob.glob(f'{img_dir}*_img.tif'))\n",
    "mask_files = sorted(glob.glob(f'{img_dir}*mask.tif'))\n",
    "img_id = [item.split('/')[-1][:4] for item in img_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459e5eec-1ea7-4e46-a75a-76d0f901ef16",
   "metadata": {},
   "source": [
    "#### load test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89f40788-6683-49f9-b962-dac3d1e9b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./val_train.pkl', 'rb') as f:\n",
    "    val_train_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "684d5b4b-e0fb-414f-992b-da00b2565e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/mnt/ampa02_data01/tmurakami/240417_whole_4color_1st_M037-3pb/fused/fused.n5',\n",
       " '/mnt/ampa02_data01/tmurakami/240425_whole_4color_2nd_M037-3pb/fused/fused.n5'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optional run, check source of data\n",
    "set(val_train_df['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "429cf24c-36c5-4bfc-a2f5-2b957a7f3d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = val_train_df['ID'].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0473326-4c0d-4ad3-842e-078973ba1cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_id = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf402e3-bbd9-47b2-8bfb-ae38ba6f2f52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0221 with the position [1197, 3800, 4884]\n"
     ]
    }
   ],
   "source": [
    "for ori_id in id_list[begin_id+10:]:\n",
    "    ori_corner_position = [val_train_df['corner'][int(ori_id)]]\n",
    "    ori_plane = int(val_train_df['plane_position'][int(ori_id)])\n",
    "    segment_chan = int(val_train_df['channel'][int(ori_id)])\n",
    "    reference_chan =  int(val_train_df['ref_channel'][int(ori_id)])\n",
    "    #check which source it should be int 0 or 1\n",
    "    brain_source = int(val_train_df['source'][int(ori_id)].split('/')[-3].split('_')[-2][0])-1\n",
    "    \n",
    "    pos = ori_corner_position[0]\n",
    "    if len(pos) <= 2:\n",
    "        raise ValueError('The position should have length 3')\n",
    "    elif len(pos) == 3:\n",
    "        isHard = 0\n",
    "    elif len(pos) == 4:\n",
    "        isHard = pos[-1]\n",
    "        pos = pos[:-1]\n",
    "    else:\n",
    "        raise ValueError('You have a wrong position format')\n",
    "        \n",
    "    print(f\"The index {ori_id} with the position {pos}\")\n",
    "    idx = int(ori_id)\n",
    "\n",
    "    z_index = int((pos[0]+ori_plane)*scale_size[0])\n",
    "    # prepare to make border lines\n",
    "    a = [1, pos[1]*scale_size[1], pos[2]*scale_size[2]]\n",
    "    b = [1, (pos[1]+256)*scale_size[1], (pos[2]+256)*scale_size[2]]\n",
    "    top_border_corner = tuple(a)\n",
    "    bottom_border_corner = tuple(b)\n",
    "   \n",
    "    #### full brain plane\n",
    "    zarr_array = fix_zarr[brain_source][n5_setups[segment_chan]]['timepoint0']['s2']\n",
    "    selected_plane_1 = zarr_array[z_index, :, :]\n",
    "    zarr_array = fix_zarr[brain_source][n5_setups[reference_chan]]['timepoint0']['s2']\n",
    "    selected_plane_2 = zarr_array[z_index, :, :]\n",
    "    #blue_image = np.full_like(zarr_array[0, :, :], fill_value=255)\n",
    "    viewer1 = napari.Viewer()\n",
    "    \n",
    "    @viewer1.bind_key('q')\n",
    "    def close_viewer(viewer):\n",
    "        print(\"Closing viewer...\")\n",
    "        viewer.close()\n",
    "\n",
    "     #set hide hotkey\n",
    "    @viewer1.bind_key('h')\n",
    "    def toggle_layer_visibility(viewer):\n",
    "        layer = viewer.layers.selection.active\n",
    "        if layer is not None:\n",
    "            layer.visible = not layer.visible\n",
    "    \n",
    "    #data3 = np.zeros(shape, dtype=np.uint8)\n",
    "    # Initialize the first Napari viewer and add the first Z-plane\n",
    "   \n",
    "    viewer1.add_image(selected_plane_1, name=f'Z-plane {ori_plane}', colormap='gray',opacity = 0.5)\n",
    "\n",
    "    viewer1.add_image(selected_plane_2, name=f'Z-plane {ori_plane}', colormap='gray',opacity = 0.5)\n",
    "    #viewer1.add_image(blue_image, name='Cover Layer')\n",
    "    viewer1.add_shapes([[bottom_border_corner[1],bottom_border_corner[2]],[top_border_corner[1],bottom_border_corner[2]]],\n",
    "                      edge_width=2,edge_color='white',ndim=2,shape_type='line')\n",
    "    viewer1.add_shapes([[top_border_corner[1],bottom_border_corner[2]],[top_border_corner[1],top_border_corner[2]]],\n",
    "                  edge_width=2,edge_color='white',ndim=2,shape_type='line')\n",
    "    viewer1.add_shapes([[bottom_border_corner[1],bottom_border_corner[2]],[bottom_border_corner[1],top_border_corner[2]]],\n",
    "                  edge_width=2,edge_color='white',ndim=2,shape_type='line')\n",
    "    viewer1.add_shapes([[bottom_border_corner[1],top_border_corner[2]],[top_border_corner[1],top_border_corner[2]]],\n",
    "                  edge_width=2,edge_color='white',ndim=2,shape_type='line') \n",
    " \n",
    "    # find out any duplication between the current data and the metadata\n",
    "    # if it is duplicated, ask \n",
    "    flag = False\n",
    "    if df['corner'].isin([pos]).any():\n",
    "        for k in df['integer_ID'][df['corner'].isin([pos])].to_list():\n",
    "            if ((df.loc[k,'source'] == fix_n5_path[brain_source]) and \n",
    "                (df.loc[k,'ref_channel'] == reference_chan) and \n",
    "                (df.loc[k,'channel'] == segment_chan) and \n",
    "                (df.loc[k,'crop_size'] == crop_size) and\n",
    "                (df.loc[k,'select_plane'] == select_plane)):\n",
    "                flag = True\n",
    "                idx = k\n",
    "    if flag:\n",
    "        ans = input(\"Do you want to re-analyze the data? y or n\")\n",
    "        if ans != 'y':\n",
    "            continue\n",
    "        \n",
    "    # set file path to be saved for both image and mask\n",
    "    prefix = str(idx)\n",
    "    while len(prefix) < 4:\n",
    "        prefix = '0' + prefix\n",
    "    img_path = os.path.join(save_path, prefix+'_img.tif')\n",
    "    mask_path = os.path.join(save_path, prefix+'_mask.tif')\n",
    "    # get the image of a channel to be segmented\n",
    "    FoV_stack = []\n",
    "    img = fix_zarr[brain_source][n5_setups[segment_chan]]['timepoint0']['s0']\n",
    "\n",
    "    # set the corner of FoV in napari\n",
    "    top_corner = tuple(i-(k-j)//2 for i,j,k in zip(pos, crop_size, FoV))\n",
    "    bottom_corner = tuple(i+j+(k-j)//2 for i,j,k in zip(pos, crop_size, FoV))\n",
    "    top_corner = tuple(j if j>=i else i for i,j in zip([0,0,0],top_corner))\n",
    "    bottom_corner = tuple(j if j<=i else i for i,j in zip(img.shape,bottom_corner))\n",
    "    \n",
    "    # prepare to make border lines\n",
    "    top_border_corner = tuple((k-j)//2 for j,k in zip(crop_size, FoV))\n",
    "    bottom_border_corner = tuple(j+(k-j)//2 for j,k in zip(crop_size, FoV))\n",
    "    \n",
    "    FoV_segment = img[tuple(slice(i,j) for i,j in zip(top_corner, bottom_corner))]\n",
    "   \n",
    "    # get the image of a reference of channel\n",
    "    if reference_chan is not None:\n",
    "        img = fix_zarr[brain_source][n5_setups[reference_chan]]['timepoint0']['s0']\n",
    "        FoV_reference = img[tuple(slice(i,j) for i,j in zip(top_corner, bottom_corner))]\n",
    "        FoV_stack.append(FoV_reference)\n",
    "    \n",
    "    FoV_stack.append(FoV_segment)\n",
    "    FoV_stack = np.stack(FoV_stack)\n",
    "\n",
    "    ##### FoV is a 2channel(reference and signal) Field of view\n",
    "    # open Napari. Pause for loop until close the window\n",
    "\n",
    "    ## add label layer data\n",
    "    shape = (100, 768, 768)\n",
    "    data = np.zeros(shape, dtype=np.uint8)\n",
    "    viewer = napari.Viewer()\n",
    "\n",
    "    @viewer.bind_key('q')\n",
    "    def close_viewer(viewer):\n",
    "        print(\"Closing viewer...\")\n",
    "        viewer.close()\n",
    "\n",
    "     #set hide hotkey\n",
    "    @viewer.bind_key('h')\n",
    "    def toggle_layer_visibility(viewer):\n",
    "        layer = viewer.layers.selection.active\n",
    "        if layer is not None:\n",
    "            layer.visible = not layer.visible\n",
    "\n",
    "    viewer.add_image(FoV_stack, channel_axis=0, scale=voxel_size, contrast_limits=[0,65535])\n",
    "    viewer.add_shapes([[bottom_border_corner[1]*voxel_size[1],bottom_border_corner[2]*voxel_size[2]],[top_border_corner[1]*voxel_size[1],bottom_border_corner[2]*voxel_size[2]]],\n",
    "                      edge_width=2,edge_color='white',ndim=2,shape_type='line')\n",
    "    viewer.add_shapes([[top_border_corner[1]*voxel_size[1],bottom_border_corner[2]*voxel_size[2]],[top_border_corner[1]*voxel_size[1],top_border_corner[2]*voxel_size[2]]],\n",
    "                  edge_width=2,edge_color='white',ndim=2,shape_type='line')\n",
    "    viewer.add_shapes([[bottom_border_corner[1]*voxel_size[1],bottom_border_corner[2]*voxel_size[2]],[bottom_border_corner[1]*voxel_size[1],top_border_corner[2]*voxel_size[2]]],\n",
    "                  edge_width=2,edge_color='white',ndim=2,shape_type='line')\n",
    "    viewer.add_shapes([[bottom_border_corner[1]*voxel_size[1],top_border_corner[2]*voxel_size[2]],[top_border_corner[1]*voxel_size[1],top_border_corner[2]*voxel_size[2]]],\n",
    "                  edge_width=2,edge_color='white',ndim=2,shape_type='line') \n",
    "\n",
    "    labels_class1 = viewer.add_labels(data,  name=f'Label({ori_plane})', scale=voxel_size)\n",
    "    labels_class1.opacity = 1.0\n",
    "    labels_class1.brush_size = 1\n",
    "\n",
    "    viewer.camera.zoom = 1.5\n",
    "    viewer.dims.current_step = (ori_plane,400,400)\n",
    "    \n",
    "    viewer.show(block=True)\n",
    "    \n",
    "    sub_area_slicer = tuple(slice(i,j) for i,j in zip(top_border_corner,bottom_border_corner))\n",
    "    ######\n",
    "    # subarea shape\n",
    "    # save images and segmentation.\n",
    "    img = np.swapaxes(FoV_stack[(slice(0,None),)+sub_area_slicer],0,1)\n",
    "    ######\n",
    "    # modify this to cellpose label\n",
    "    #labels_img = labels.data[sub_area_slicer]\n",
    "    labels_img_class1 = labels_class1.data[sub_area_slicer]\n",
    "    \n",
    "    if select_plane:\n",
    "        print('selected and save')\n",
    "        ##########\n",
    "        # modify this to original label\n",
    "        plane_pos = np.argmax((labels_class1.data>0).sum(axis=(1,2)))\n",
    "        img = img[plane_pos,...]\n",
    "        labels_img_class1 = labels_img_class1[plane_pos,...]\n",
    "        io.imsave(img_path, img, plugin='tifffile', imagej=True, metadata={'axes': 'CYX'})\n",
    "        io.imsave(mask_path, labels_img_class1, plugin='tifffile')\n",
    "        \n",
    "\n",
    "    else:\n",
    "        print('#############')\n",
    "        print('not selected and save')\n",
    "        io.imsave(img_path, img, plugin='tifffile', imagej=True, metadata={'axes': 'ZCYX'})\n",
    "\n",
    "    # update the metadata\n",
    "    df.loc[idx,'ID'] = prefix\n",
    "    df.loc[idx,'integer_ID'] = idx\n",
    "    count = (np.unique(labels_img_class1)).size - 1\n",
    "    df.loc[idx,'instance_counts'] = count\n",
    "    df.at[idx,'corner'] = pos\n",
    "    df.loc[idx, 'source'] = fix_n5_path[brain_source]\n",
    "    df.loc[idx, 'ref_channel'] = reference_chan\n",
    "    df.loc[idx, 'channel'] = segment_chan\n",
    "    df.at[idx, 'crop_size'] = crop_size\n",
    "    df.loc[idx, 'select_plane'] = select_plane\n",
    "    df.loc[idx, 'isHard'] = isHard\n",
    "    if select_plane:\n",
    "        df.loc[idx, 'plane_position'] = int(plane_pos)\n",
    "    else:\n",
    "        df.loc[idx, 'plane_position'] = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "690e4ecf-1a0f-4ef6-b0c1-9df93fa87415",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f23c3dd1-265d-4089-b1b8-839a1a16d9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " id_list.index('0158')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d108ee8-bb65-44ec-aeab-521693a50185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff329081-757d-4f92-a015-166f47cb9601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current image id 46, next begin id 46\n"
     ]
    }
   ],
   "source": [
    "# if you don't want to run all again, set the beginning id as begin\n",
    "curent_id = id_list.index(ori_id)\n",
    "begin_id = curent_id\n",
    "print(f'current image id {curent_id}, next begin id {begin_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3d4bdb5-da67-404a-9dc1-db072ef554b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional)if you want to start all over again, reset begin_id as 0\n",
    "# begin_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d4c466-e646-43c3-9f3a-534eb1f7baff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
