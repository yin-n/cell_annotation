{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d8cbe40-4b8a-4daa-9482-4f3a1be268ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "import napari\n",
    "import pandas as pd\n",
    "import zarr\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tf\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f820e5d1-a6ab-4900-a97e-967646eceded",
   "metadata": {},
   "source": [
    "### Get Annotation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3b40fd2-9e1b-4561-a547-677757e2370b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_932987/3047246091.py:9: FutureWarning: The N5Store is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "  fix_zarr = [zarr.open(store=zarr.N5Store(fix_n5_path[0]), mode='r'), zarr.open(store=zarr.N5Store(fix_n5_path[1]), mode='r')]\n"
     ]
    }
   ],
   "source": [
    "fix_n5_path = ['/mnt/aperto/fused/fused.n5','/mnt/aperto/Tatz_brain_data/fused/fused.n5']\n",
    "directory = './tatz_anno_2d_cplm/'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    print(\"Directory created:\", directory)\n",
    "save_path = directory\n",
    "meta_path = './tatz_anno_2d_cplm/tatz_anno_2d_cplm.pkl'\n",
    "# create Zarr file object\n",
    "fix_zarr = [zarr.open(store=zarr.N5Store(fix_n5_path[0]), mode='r'), zarr.open(store=zarr.N5Store(fix_n5_path[1]), mode='r')]\n",
    "n5_setups = list(fix_zarr[0].keys())\n",
    "voxel_size = (2.0,1.3,1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a62f4fe5-a1db-46b2-b4b0-0e5b635b3f5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make metadata file if it does not exist.\n",
    "if not os.path.exists(meta_path):\n",
    "    df = pd.DataFrame(columns=['ID', 'integer_ID', 'instance_counts', 'corner', 'source', 'ref_channel', 'channel', 'crop_size', 'isHard', 'plane_position','model'])\n",
    "else:\n",
    "    df = pd.read_pickle(meta_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f33f7d2-82b1-48b4-aef2-7b9998f913df",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolusion_0_shape = fix_zarr[0][n5_setups[1]]['timepoint0']['s0'].shape\n",
    "resolusion_2_shape = fix_zarr[0][n5_setups[3]]['timepoint0']['s2'].shape\n",
    "scale_size = []\n",
    "for i in range(len(resolusion_0_shape)):\n",
    "    scale_size.append(resolusion_2_shape[i]/resolusion_0_shape[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4e51507-0a99-4f5d-b8e5-03b3ba5f07bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your parameters here\n",
    "reference_chan = 3 # Integer or None\n",
    "segment_chan = 4\n",
    "\n",
    "# [100,256,256] crop size and FoV [100,768,768] are recommended for the 2D annotation\n",
    "crop_size = [100,256,256]\n",
    "FoV = [100,768, 768]\n",
    "FoV1 = [1, 2137, 1603]\n",
    "# set True for 2D annotation and set False for 3D annotation\n",
    "select_plane = True\n",
    "\n",
    "# processing of parameters\n",
    "if not all([(j-i)>=0 for i,j in zip(crop_size, FoV)]):\n",
    "    raise ValueError('FoV should be larger than crop_size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459e5eec-1ea7-4e46-a75a-76d0f901ef16",
   "metadata": {},
   "source": [
    "#### load ori 234 dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89f40788-6683-49f9-b962-dac3d1e9b970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_932987/3875984921.py:2: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  ori_234_train = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "with open('./annotation_position_info.pkl', 'rb') as f:\n",
    "    ori_234_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6453dba0-2c5b-487e-8584-c69ac5dd8300",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_77 = pd.read_csv('./selection77.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84754ee1-568c-48bd-ae77-c751cdf8360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_anno = sel_77[sel_77['Re-annotation (y or n)'] == 'y'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cebf25a5-1612-482a-bd94-afe0e3ce7638",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pos_77.pkl', 'rb') as f:\n",
    "    pos_id = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7b568b8-fb9b-40c7-bdce-55fdec6f0cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1b8989d-e1b4-4884-9477-cc52bd6c88d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pos_id)):\n",
    "    if i in re_anno:\n",
    "        id_list.append(pos_id[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdfb2e66-2d7b-4b2e-9cce-66d1a3a352cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### img need 3d view\n",
    "img_3d_vu = [10,13,14,16,17,33,39,44,68,74,76] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2911d21-b0f3-48c6-90d3-8d57f9b68544",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in img_3d_vu:\n",
    "  id_list.append(pos_id[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "429cf24c-36c5-4bfc-a2f5-2b957a7f3d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b505ef-d8b1-4cbe-b6db-72e497e506c2",
   "metadata": {},
   "source": [
    "#### load cellpose, stardist, swin label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55cde8e2-2a55-4c22-a8ea-1be9ebc8392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./cellpose_training_tatz.pkl', 'rb') as f:\n",
    "    cellpose_training_all = pickle.load(f)\n",
    "    \n",
    "with open('./stardist_training_tatz.pkl', 'rb') as f:\n",
    "    stardist_training_all = pickle.load(f)\n",
    "\n",
    "cellpose, stardist = cellpose_training_all, stardist_training_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8e6baeb-a09f-40c3-9a60-233c37da4548",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./swin_training_tatz.pkl', 'rb') as f:\n",
    "    swin2d = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8cea63-fe68-48b5-90b6-c22703474b54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0473326-4c0d-4ad3-842e-078973ba1cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bf402e3-bbd9-47b2-8bfb-ae38ba6f2f52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0126 with the position [93, 4958, 4866]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_932987/723882817.py:226: UserWarning: ./tatz_anno_2d_cplm/0126_nw_mask.tif is a low contrast image\n",
      "  io.imsave(mask_path[0], re_anno_res, plugin='tifffile')\n",
      "/tmp/ipykernel_932987/723882817.py:227: UserWarning: ./tatz_anno_2d_cplm/0126_cp_mask.tif is a low contrast image\n",
      "  io.imsave(mask_path[1], cp_anno_res, plugin='tifffile')\n",
      "/tmp/ipykernel_932987/723882817.py:228: UserWarning: ./tatz_anno_2d_cplm/0126_sd_mask.tif is a low contrast image\n",
      "  io.imsave(mask_path[2], sd_anno_res, plugin='tifffile')\n",
      "/tmp/ipykernel_932987/723882817.py:229: UserWarning: ./tatz_anno_2d_cplm/0126_sw_mask.tif is a low contrast image\n",
      "  io.imsave(mask_path[3], sw_anno_res, plugin='tifffile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected and save\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "which model you will re-annotate?(cp, sd, sw, n)? sw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0191 with the position [586, 6230, 3173]\n",
      "Closing viewer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yyin/miniconda3/envs/annotate/lib/python3.10/site-packages/napari/viewer.py:192: RuntimeWarning: The window geometry settings could not be loaded due to the following error: 'Window' object has no attribute '_qt_window'\n",
      "  self.window.show(block=block)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Window' object has no attribute '_qt_window'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 193\u001b[0m\n\u001b[1;32m    191\u001b[0m viewer\u001b[38;5;241m.\u001b[39mcamera\u001b[38;5;241m.\u001b[39mzoom \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.5\u001b[39m\n\u001b[1;32m    192\u001b[0m viewer\u001b[38;5;241m.\u001b[39mdims\u001b[38;5;241m.\u001b[39mcurrent_step \u001b[38;5;241m=\u001b[39m (ori_plane,\u001b[38;5;241m400\u001b[39m,\u001b[38;5;241m400\u001b[39m)\n\u001b[0;32m--> 193\u001b[0m \u001b[43mviewer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m sub_area_slicer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i,j) \u001b[38;5;28;01mfor\u001b[39;00m i,j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(top_border_corner,bottom_border_corner))\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m######\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# subarea shape\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# save images and segmentation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/annotate/lib/python3.10/site-packages/napari/viewer.py:192\u001b[0m, in \u001b[0;36mViewer.show\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, block\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    191\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Resize, show, and raise the viewer window.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/annotate/lib/python3.10/site-packages/napari/_qt/qt_main_window.py:1472\u001b[0m, in \u001b[0;36mWindow.show\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1461\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1462\u001b[0m             trans\u001b[38;5;241m.\u001b[39m_(\n\u001b[1;32m   1463\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe window geometry settings could not be loaded due to the following error: \u001b[39m\u001b[38;5;132;01m{err}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1468\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1469\u001b[0m         )\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;66;03m# Resize axis labels now that window is shown\u001b[39;00m\n\u001b[0;32m-> 1472\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_qt_viewer\u001b[49m\u001b[38;5;241m.\u001b[39mdims\u001b[38;5;241m.\u001b[39m_resize_axis_labels()\n\u001b[1;32m   1474\u001b[0m \u001b[38;5;66;03m# We want to bring the viewer to the front when\u001b[39;00m\n\u001b[1;32m   1475\u001b[0m \u001b[38;5;66;03m# A) it is our own event loop OR we are running in jupyter\u001b[39;00m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;66;03m# B) it is not the first time a QMainWindow is being created\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[38;5;66;03m# _qt_window has been created.\u001b[39;00m\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;66;03m# See #721, #732, #735, #795, #1594\u001b[39;00m\n\u001b[1;32m   1482\u001b[0m app_name \u001b[38;5;241m=\u001b[39m QApplication\u001b[38;5;241m.\u001b[39minstance()\u001b[38;5;241m.\u001b[39mapplicationName()\n",
      "File \u001b[0;32m~/miniconda3/envs/annotate/lib/python3.10/site-packages/napari/_qt/qt_main_window.py:821\u001b[0m, in \u001b[0;36mWindow._qt_viewer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_qt_viewer\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# this is starting to be \"vestigial\"... this property could be removed\u001b[39;00m\n\u001b[0;32m--> 821\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_qt_window\u001b[49m\u001b[38;5;241m.\u001b[39m_qt_viewer\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Window' object has no attribute '_qt_window'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing viewer...\n"
     ]
    }
   ],
   "source": [
    "for ori_id in id_list[begin_id:]:\n",
    "    ori_corner_position = [ori_234_train['corner'][int(ori_id)]]\n",
    "    ori_plane = int(ori_234_train['plane_position'][int(ori_id)])\n",
    "    segment_chan = int(ori_234_train['channel'][int(ori_id)])\n",
    "    reference_chan =  int(ori_234_train['ref_channel'][int(ori_id)])\n",
    "    #check which source it should be int 0 or 1\n",
    "    brain_source = int(ori_234_train['source'][int(ori_id)].split('/')[-3].split('_')[-2][0])-1\n",
    "    \n",
    "    pos = ori_corner_position[0]\n",
    "    if len(pos) <= 2:\n",
    "        raise ValueError('The position should have length 3')\n",
    "    elif len(pos) == 3:\n",
    "        isHard = 0\n",
    "    elif len(pos) == 4:\n",
    "        isHard = pos[-1]\n",
    "        pos = pos[:-1]\n",
    "    else:\n",
    "        raise ValueError('You have a wrong position format')\n",
    "        \n",
    "    print(f\"The index {ori_id} with the position {pos}\")\n",
    "    idx = int(ori_id)\n",
    "\n",
    "    z_index = int((pos[0]+ori_plane)*scale_size[0])\n",
    "    # prepare to make border lines\n",
    "    a = [1, pos[1]*scale_size[1], pos[2]*scale_size[2]]\n",
    "    b = [1, (pos[1]+256)*scale_size[1], (pos[2]+256)*scale_size[2]]\n",
    "    top_border_corner = tuple(a)\n",
    "    bottom_border_corner = tuple(b)\n",
    "   \n",
    "    #### full brain plane\n",
    "    zarr_array = fix_zarr[brain_source][n5_setups[segment_chan]]['timepoint0']['s2']\n",
    "    selected_plane_1 = zarr_array[z_index, :, :]\n",
    "    zarr_array = fix_zarr[brain_source][n5_setups[reference_chan]]['timepoint0']['s2']\n",
    "    selected_plane_2 = zarr_array[z_index, :, :]\n",
    "    #blue_image = np.full_like(zarr_array[0, :, :], fill_value=255)\n",
    "    \n",
    "    viewer1 = napari.Viewer()\n",
    "    \n",
    "    @viewer1.bind_key('q')\n",
    "    def close_viewer(viewer):\n",
    "        print(\"Closing viewer...\")\n",
    "        viewer.close()\n",
    "\n",
    "     #set hide hotkey\n",
    "    @viewer1.bind_key('h')\n",
    "    def toggle_layer_visibility(viewer):\n",
    "        layer = viewer.layers.selection.active\n",
    "        if layer is not None:\n",
    "            layer.visible = not layer.visible\n",
    "    \n",
    "    #data3 = np.zeros(shape, dtype=np.uint8)\n",
    "    # Initialize the first Napari viewer and add the first Z-plane\n",
    "   \n",
    "    viewer1.add_image(selected_plane_1, name=f'Z-plane {ori_plane}', colormap='gray',opacity = 0.5)\n",
    "\n",
    "    viewer1.add_image(selected_plane_2, name=f'Z-plane {ori_plane}', colormap='gray',opacity = 0.5)\n",
    "    #viewer1.add_image(blue_image, name='Cover Layer')\n",
    "    viewer1.add_shapes([[bottom_border_corner[1],bottom_border_corner[2]],[top_border_corner[1],bottom_border_corner[2]]],\n",
    "                      edge_width=2,edge_color='white',ndim=2,shape_type='line')\n",
    "    viewer1.add_shapes([[top_border_corner[1],bottom_border_corner[2]],[top_border_corner[1],top_border_corner[2]]],\n",
    "                  edge_width=2,edge_color='white',ndim=2,shape_type='line')\n",
    "    viewer1.add_shapes([[bottom_border_corner[1],bottom_border_corner[2]],[bottom_border_corner[1],top_border_corner[2]]],\n",
    "                  edge_width=2,edge_color='white',ndim=2,shape_type='line')\n",
    "    viewer1.add_shapes([[bottom_border_corner[1],top_border_corner[2]],[top_border_corner[1],top_border_corner[2]]],\n",
    "                  edge_width=2,edge_color='white',ndim=2,shape_type='line') \n",
    " \n",
    "    # find out any duplication between the current data and the metadata\n",
    "    # if it is duplicated, ask \n",
    "    flag = False\n",
    "    if df['corner'].isin([pos]).any():\n",
    "        for k in df['integer_ID'][df['corner'].isin([pos])].to_list():\n",
    "            if ((df.loc[k,'source'] == fix_n5_path[brain_source]) and \n",
    "                (df.loc[k,'ref_channel'] == reference_chan) and \n",
    "                (df.loc[k,'channel'] == segment_chan) and \n",
    "                (df.loc[k,'crop_size'] == crop_size) and\n",
    "                (df.loc[k,'select_plane'] == select_plane)):\n",
    "                flag = True\n",
    "                idx = k\n",
    "    if flag:\n",
    "        ans = input(\"Do you want to re-analyze the data? y or n\")\n",
    "       \n",
    "        if ans != 'y':\n",
    "            continue\n",
    "\n",
    "\n",
    "  \n",
    "    # set file path to be saved for both image and mask\n",
    "    prefix = str(idx)\n",
    "    while len(prefix) < 4:\n",
    "        prefix = '0' + prefix\n",
    "    img_path = os.path.join(save_path, prefix+'_img.tif')\n",
    "    #mask_path = os.path.join(save_path, prefix+'_mask.tif')\n",
    "    mask_path = [os.path.join(save_path, prefix+'_nw_mask.tif'),os.path.join(save_path, prefix+'_cp_mask.tif'), \n",
    "                 os.path.join(save_path, prefix+'_sd_mask.tif'), os.path.join(save_path, prefix+'_sw_mask.tif')]\n",
    "    # get the image of a channel to be segmented\n",
    "    FoV_stack = []\n",
    "    img = fix_zarr[brain_source][n5_setups[segment_chan]]['timepoint0']['s0']\n",
    "\n",
    "    # set the corner of FoV in napari\n",
    "    top_corner = tuple(i-(k-j)//2 for i,j,k in zip(pos, crop_size, FoV))\n",
    "    bottom_corner = tuple(i+j+(k-j)//2 for i,j,k in zip(pos, crop_size, FoV))\n",
    "    top_corner = tuple(j if j>=i else i for i,j in zip([0,0,0],top_corner))\n",
    "    bottom_corner = tuple(j if j<=i else i for i,j in zip(img.shape,bottom_corner))\n",
    "    \n",
    "    # prepare to make border lines\n",
    "    top_border_corner = tuple((k-j)//2 for j,k in zip(crop_size, FoV))\n",
    "    bottom_border_corner = tuple(j+(k-j)//2 for j,k in zip(crop_size, FoV))\n",
    "    \n",
    "    FoV_segment = img[tuple(slice(i,j) for i,j in zip(top_corner, bottom_corner))]\n",
    "    # get the image of a reference of channel\n",
    "    if reference_chan is not None:\n",
    "        img = fix_zarr[brain_source][n5_setups[reference_chan]]['timepoint0']['s0']\n",
    "        FoV_reference = img[tuple(slice(i,j) for i,j in zip(top_corner, bottom_corner))]\n",
    "        FoV_stack.append(FoV_reference)\n",
    "    \n",
    "    FoV_stack.append(FoV_segment)\n",
    "    FoV_stack = np.stack(FoV_stack)\n",
    "\n",
    "    ##### FoV is a 2channel(reference and signal) Field of view\n",
    "\n",
    "    ## add label layer data\n",
    "    shape = (100, 768, 768)\n",
    "    data = np.zeros(shape, dtype=np.uint16)\n",
    "    \n",
    "    ### add psesudo labels\n",
    "    # cellpose\n",
    "    cp_pseudo = np.zeros(shape, dtype=np.uint16)\n",
    "    cp_pseudo[ori_plane,256:512,256:512] = cellpose[ori_id]\n",
    "\n",
    "\n",
    "    # stardist\n",
    "    sd_pseudo = np.zeros(shape, dtype=np.uint16)\n",
    "    sd_pseudo[ori_plane,256:512,256:512] = stardist[ori_id]\n",
    "\n",
    "\n",
    "    # swin\n",
    "\n",
    "    sw_pseudo =  np.zeros(shape, dtype=np.uint16)\n",
    "    sw_pseudo[ori_plane,256:512,256:512] = swin2d[ori_id]\n",
    "\n",
    "    viewer = napari.Viewer()\n",
    "\n",
    "      ### choose model\n",
    "\n",
    "\n",
    "    @viewer.bind_key('q')\n",
    "    def close_viewer(viewer):\n",
    "        print(\"Closing viewer...\")\n",
    "        viewer.close()\n",
    "\n",
    "     #set hide hotkey\n",
    "    @viewer.bind_key('h')\n",
    "    def toggle_layer_visibility(viewer):\n",
    "        layer = viewer.layers.selection.active\n",
    "        if layer is not None:\n",
    "            layer.visible = not layer.visible\n",
    "\n",
    "    viewer.add_image(FoV_stack, channel_axis=0, scale=voxel_size, contrast_limits=[0,65535])\n",
    "    viewer.add_shapes([[bottom_border_corner[1]*voxel_size[1],bottom_border_corner[2]*voxel_size[2]],[top_border_corner[1]*voxel_size[1],bottom_border_corner[2]*voxel_size[2]]],\n",
    "                      edge_width=2,edge_color='white',ndim=2,shape_type='line')\n",
    "    viewer.add_shapes([[top_border_corner[1]*voxel_size[1],bottom_border_corner[2]*voxel_size[2]],[top_border_corner[1]*voxel_size[1],top_border_corner[2]*voxel_size[2]]],\n",
    "                  edge_width=2,edge_color='white',ndim=2,shape_type='line')\n",
    "    viewer.add_shapes([[bottom_border_corner[1]*voxel_size[1],bottom_border_corner[2]*voxel_size[2]],[bottom_border_corner[1]*voxel_size[1],top_border_corner[2]*voxel_size[2]]],\n",
    "                  edge_width=2,edge_color='white',ndim=2,shape_type='line')\n",
    "    viewer.add_shapes([[bottom_border_corner[1]*voxel_size[1],top_border_corner[2]*voxel_size[2]],[top_border_corner[1]*voxel_size[1],top_border_corner[2]*voxel_size[2]]],\n",
    "                  edge_width=2,edge_color='white',ndim=2,shape_type='line') \n",
    "\n",
    "    re_anno_label = viewer.add_labels(data,  name=f'Label({ori_plane})', scale=voxel_size)\n",
    "    re_anno_label.opacity = 1.0\n",
    "    re_anno_label.brush_size = 1\n",
    "\n",
    "\n",
    "\n",
    "    ### cellpose\n",
    "    cp_labels = viewer.add_labels(cp_pseudo,  name=f'cellpose({ori_plane})', scale=voxel_size)\n",
    "    cp_labels.opacity = 1.0\n",
    "    cp_labels.brush_size = 1\n",
    "\n",
    "\n",
    "    ### stardist\n",
    "    sd_labels = viewer.add_labels(sd_pseudo,  name=f'stardist({ori_plane})', scale=voxel_size)\n",
    "    sd_labels.opacity = 1.0\n",
    "    sd_labels.brush_size = 1\n",
    "\n",
    "\n",
    "    ### swin\n",
    "    sw_labels = viewer.add_labels(sw_pseudo,  name=f'swin2d({ori_plane})', scale=voxel_size)\n",
    "    sw_labels.opacity = 1.0\n",
    "    sw_labels.brush_size = 1\n",
    "\n",
    "    viewer.camera.zoom = 1.5\n",
    "    viewer.dims.current_step = (ori_plane,400,400)\n",
    "    viewer.show(block=True)\n",
    "\n",
    "    sub_area_slicer = tuple(slice(i,j) for i,j in zip(top_border_corner,bottom_border_corner))\n",
    "    ######\n",
    "    # subarea shape\n",
    "    # save images and segmentation.\n",
    "    img = np.swapaxes(FoV_stack[(slice(0,None),)+sub_area_slicer],0,1)\n",
    "    #label layer\n",
    "    re_anno_res = re_anno_label.data[sub_area_slicer]\n",
    "    ### cellpose\n",
    "    cp_anno_res = cp_labels.data[sub_area_slicer]\n",
    "    ### stardist\n",
    "    sd_anno_res = sd_labels.data[sub_area_slicer]\n",
    "\n",
    "    ### swin\n",
    "    sw_anno_res = sw_labels.data[sub_area_slicer]\n",
    "    \n",
    "    \n",
    "    if select_plane:\n",
    "        print('selected and save')\n",
    "        ##########\n",
    "        # modify this to original label\n",
    "        plane_pos = ori_plane\n",
    "        img = img[plane_pos,...]\n",
    "        re_anno_res = re_anno_res[plane_pos,...]\n",
    "        #cp,sd,sw\n",
    "        cp_anno_res = cp_anno_res[plane_pos,...]\n",
    "        sd_anno_res = sd_anno_res[plane_pos,...]\n",
    "        sw_anno_res = sw_anno_res[plane_pos,...]\n",
    "        \n",
    "\n",
    "        io.imsave(img_path, img, plugin='tifffile', imagej=True, metadata={'axes': 'CYX'})\n",
    "        ### save masks\n",
    "        io.imsave(mask_path[0], re_anno_res, plugin='tifffile')\n",
    "        io.imsave(mask_path[1], cp_anno_res, plugin='tifffile')\n",
    "        io.imsave(mask_path[2], sd_anno_res, plugin='tifffile')\n",
    "        io.imsave(mask_path[3], sw_anno_res, plugin='tifffile')\n",
    "        \n",
    "    else:\n",
    "        print('#############')\n",
    "        print('not selected and save')\n",
    "        io.imsave(img_path, img, plugin='tifffile', imagej=True, metadata={'axes': 'ZCYX'})\n",
    "\n",
    "    \n",
    "    model = input(\"which model you will re-annotate?(cp, sd, sw, n)?\")\n",
    "\n",
    "    # update the metadata\n",
    "    df.loc[idx,'ID'] = prefix\n",
    "    df.loc[idx,'integer_ID'] = idx\n",
    "    count = (np.unique(re_anno_res)).size - 1\n",
    "    df.loc[idx,'instance_counts'] = count\n",
    "    df.at[idx,'corner'] = pos\n",
    "    df.loc[idx, 'source'] = fix_n5_path[brain_source]\n",
    "    df.loc[idx, 'ref_channel'] = reference_chan\n",
    "    df.loc[idx, 'channel'] = segment_chan\n",
    "    df.at[idx, 'crop_size'] = crop_size\n",
    "    df.loc[idx, 'select_plane'] = select_plane\n",
    "    df.loc[idx, 'isHard'] = isHard\n",
    "    df.loc[idx, 'model'] = model\n",
    "    if select_plane:\n",
    "        df.loc[idx, 'plane_position'] = int(plane_pos)\n",
    "    else:\n",
    "        df.loc[idx, 'plane_position'] = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "690e4ecf-1a0f-4ef6-b0c1-9df93fa87415",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff329081-757d-4f92-a015-166f47cb9601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current image id 46, next begin id 46\n"
     ]
    }
   ],
   "source": [
    "# if you don't want to run all again, set the beginning id as begin\n",
    "curent_id = id_list.index(ori_id)\n",
    "begin_id = curent_id\n",
    "print(f'current image id {curent_id}, next begin id {begin_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3d4bdb5-da67-404a-9dc1-db072ef554b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional)if you want to start all over again, reset begin_id as 0\n",
    "# begin_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "04d4c466-e646-43c3-9f3a-534eb1f7baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_plane = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0246ed0e-e6b9-4f32-891e-8e60fdf99ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (100, 768, 768)\n",
    "cp_pseudo = np.zeros(shape, dtype=np.uint16)\n",
    "cp_pseudo[ori_plane,256:512,256:512] = cellpose['0210']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5827fdb8-825e-484d-b70c-c41bb6bc2982",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '0021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e373119-ae38-463e-aa59-7cd2ba389d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./tatz_anno_2d_cplm/0126_nw_mask.tif',\n",
       " './tatz_anno_2d_cplm/0126_cp_mask.tif',\n",
       " './tatz_anno_2d_cplm/0126_sd_mask.tif',\n",
       " './tatz_anno_2d_cplm/0126_sw_mask.tif']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66903156-7b30-43b0-b078-fb61a5d05f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
