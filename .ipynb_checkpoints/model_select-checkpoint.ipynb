{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8d8cbe40-4b8a-4daa-9482-4f3a1be268ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "import napari\n",
    "import pandas as pd\n",
    "import zarr\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "import tiffile as tf\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f820e5d1-a6ab-4900-a97e-967646eceded",
   "metadata": {},
   "source": [
    "### Make data for training\n",
    "Assume training data is double color. One for the channel to get segmented and another for cytosol/nuclei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a3b40fd2-9e1b-4561-a547-677757e2370b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/3050946335.py:21: FutureWarning: The N5Store is deprecated and will be removed in a Zarr-Python version 3, see https://github.com/zarr-developers/zarr-python/issues/1274 for more information.\n",
      "  fix_zarr = [zarr.open(store=zarr.N5Store(fix_n5_path[0]), mode='r'), zarr.open(store=zarr.N5Store(fix_n5_path[1]), mode='r')]\n"
     ]
    }
   ],
   "source": [
    "##### change path\n",
    "# first path need to be first brain,second path need to be another brain\n",
    "fix_n5_path = ['/mnt/aperto/fused/fused.n5','/mnt/aperto/Tatz_brain_data/fused/fused.n5']\n",
    "\n",
    "# save path\n",
    "#create the directory if it does not exist\n",
    "##### change path\n",
    "# you need to change to the folder you want\n",
    "directory = './crops/'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    print(\"Directory created:\", directory)\n",
    "##### change path\n",
    "# you need to change to the folder you want\n",
    "save_path = './crops'\n",
    "##### change path\n",
    "#you need to change to the folder you want metadata path\n",
    "meta_path = './info.pkl'\n",
    "\n",
    "# create Zarr file object\n",
    "fix_zarr = [zarr.open(store=zarr.N5Store(fix_n5_path[0]), mode='r'), zarr.open(store=zarr.N5Store(fix_n5_path[1]), mode='r')]\n",
    "# if you use ngff ome.zarr\n",
    "# mov_zarr_path = '/mnt/ampa02_data01/tmurakami/240417_whole_4color_1st_M037-3pb/registration/round02.zarr'\n",
    "# mov_zarr = zarr.open(mov_zarr_path, mode='r')\n",
    "\n",
    "n5_setups = list(fix_zarr[0].keys())\n",
    "\n",
    "voxel_size = (2.0,1.3,1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c4e51507-0a99-4f5d-b8e5-03b3ba5f07bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your parameters here\n",
    "reference_chan = 3 # Integer or None\n",
    "segment_chan = 4\n",
    "\n",
    "# [100,256,256] crop size and FoV [100,768,768] are recommended for the 2D annotation\n",
    "crop_size = [100,256,256]\n",
    "FoV = [100,768,768]\n",
    "\n",
    "# set corner positions. I suggest finding the positions using BigDataViewer or relevant.\n",
    "# use the fourth column to add information\n",
    "center_positions = [\n",
    "    [1235,2510,775, 1],\n",
    "    [1325,3350,1542,2],\n",
    "    [1725,4632,1602]\n",
    "]\n",
    "\n",
    "corner_positions = [[(i-j//2) for i,j in zip(cent_pos, crop_size + [0])] for cent_pos in center_positions]\n",
    "\n",
    "# set True for 2D annotation and set False for 3D annotation\n",
    "select_plane = True\n",
    "\n",
    "# processing of parameters\n",
    "if not all([(j-i)>=0 for i,j in zip(crop_size, FoV)]):\n",
    "    raise ValueError('FoV should be larger than crop_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a62f4fe5-a1db-46b2-b4b0-0e5b635b3f5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make metadata file if it does not exist.\n",
    "if not os.path.exists(meta_path):\n",
    "    df = pd.DataFrame(columns=['ID', 'integer_ID', 'instance_counts', 'corner', 'source', 'ref_channel', 'channel', 'crop_size', 'isHard', 'plane_position','model_rank', 'comments'])\n",
    "else:\n",
    "    df = pd.read_pickle(meta_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "df5d8feb-f451-46b2-9ae8-7ddf4ddf664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have trouble like ImportError: cannot import name 'fastCopyAndTranspose' from 'numpy.core.multiarray' \n",
    "# try this\n",
    "#!pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a66934-f673-4588-a4a5-d598d537d58b",
   "metadata": {},
   "source": [
    "### Add cellpose prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5662909-c2f1-47e0-9fcd-40f74b3c091b",
   "metadata": {},
   "source": [
    "#### load original data and get the image wan to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "50dc0a2f-505c-491e-a347-e206e8efaee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/2941550060.py:2: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  ori_data = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "with open('./annotation_position_info.pkl', 'rb') as f:\n",
    "    ori_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9d2c85b8-422c-4d16-9a9b-053b483488e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all files in the directory ending with '_img.tif', and '_mask.tif' \n",
    "##### change path\n",
    "#you need to change this path to your image and mask file path\n",
    "img_dir = '/mnt/aperto/yin/cellpose_training/data/image_masks/' \n",
    "img_files = sorted(glob.glob(f'{img_dir}*_img.tif'))\n",
    "mask_files = sorted(glob.glob(f'{img_dir}*mask.tif'))\n",
    "img_id = [item.split('/')[-1][:4] for item in img_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "04a459ac-fe54-40c1-a441-cd40718f637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all the id are valid\n",
    "for item in img_id:\n",
    "    try:\n",
    "        ori_data.iloc[int(item)]\n",
    "    except:\n",
    "       print(item, 'invalid id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "684d5b4b-e0fb-414f-992b-da00b2565e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/mnt/ampa02_data01/tmurakami/240417_whole_4color_1st_M037-3pb/fused/fused.n5',\n",
       " '/mnt/ampa02_data01/tmurakami/240425_whole_4color_2nd_M037-3pb/fused/fused.n5'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optional run, check source of data\n",
    "set(ori_data['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "72d85dcb-89ac-4c08-8a81-0c55b00dda5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional run, check source of data\n",
    "source1 = []\n",
    "source2 = []\n",
    "for i in range(len(ori_data)):\n",
    "    if ori_data['source'][i].split('/')[-3] == '240417_whole_4color_1st_M037-3pb':\n",
    "        source1.append(i)\n",
    "    elif ori_data['source'][i].split('/')[-3] == '240425_whole_4color_2nd_M037-3pb':\n",
    "        source2.append(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be869a05-5992-4ef8-b8b8-4c194f4340f1",
   "metadata": {},
   "source": [
    "#### load cellpose prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6ccbe93a-02e1-4d15-93e2-519ccdd13758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to change path to your pkl path\n",
    "with open('./cellpose_nonorm_all.pkl', 'rb') as f:\n",
    "    cellpose_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3436ddae-cb8f-40fe-a2b7-8164eacba76d",
   "metadata": {},
   "source": [
    "#### load stardist results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d07f8add-0f48-49ec-a819-61264501d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./stardist_all.pkl', 'rb') as f:\n",
    "    stardist_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285b23dc-6a7a-4b54-ae42-25779f5c0c17",
   "metadata": {},
   "source": [
    "#### load swinUnetr results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9830400a-181a-4e65-9aea-b7054af824dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d7084186-6b8e-4970-b3be-2ea227c8af5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/1266532266.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  swin2d_predict[idx] = torch.load(item)['instance_mask']\n"
     ]
    }
   ],
   "source": [
    "### swinunetr_2D\n",
    "swin2d_dir = '/mnt/aperto/yin/swinunetr_results/swinunetr_2D/' \n",
    "swin2d_files = sorted(glob.glob(f'{swin2d_dir}*_img_pred.pt'))\n",
    "swin2d_predict = {}\n",
    "for item in swin2d_files:\n",
    "    idx = item.split('/')[-1].split('_')[0]\n",
    "    swin2d_predict[idx] = torch.load(item)['instance_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "32ddfa4f-1663-4000-b308-3ff8b23a3f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/1945268139.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  swin2d_pretrain_predict[idx] = torch.load(item)['instance_mask']\n"
     ]
    }
   ],
   "source": [
    "### swinunetr_pretrained_2D\n",
    "swin2d_pretrain_dir = '/mnt/aperto/yin/swinunetr_results/swinunetr_2D_pretrain/' \n",
    "swin2d_pretrain_files = sorted(glob.glob(f'{swin2d_pretrain_dir}*_img_pred.pt'))\n",
    "swin2d_pretrain_predict = {}\n",
    "for item in swin2d_pretrain_files:\n",
    "    idx = item.split('/')[-1].split('_')[0]\n",
    "    swin2d_pretrain_predict[idx] = torch.load(item)['instance_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ae0258c0-ee8d-481f-8f78-38ca17de1f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/750914079.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  swin_3D_pretrain_window3_predict[idx] = torch.load(item)['instance_mask']\n"
     ]
    }
   ],
   "source": [
    "### swinunetr_3D_window3\n",
    "swin_3D_pretrain_window3_dir = '/mnt/aperto/yin/swinunetr_results/swinunetr_3D_pretrain_window3/' \n",
    "swin_3D_pretrain_window3_files = sorted(glob.glob(f'{swin_3D_pretrain_window3_dir}*_img_pred.pt'))\n",
    "swin_3D_pretrain_window3_predict = {}\n",
    "for item in swin_3D_pretrain_window3_files:\n",
    "    idx = item.split('/')[-1].split('_')[0]\n",
    "    swin_3D_pretrain_window3_predict[idx] = torch.load(item)['instance_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5f154a97-e22e-4cde-bf20-be47082b4597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/242877275.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  swin_3D_pretrain_window7_predict[idx] = torch.load(item)['instance_mask']\n"
     ]
    }
   ],
   "source": [
    "### swinunetr_3D_window7\n",
    "swin_3D_pretrain_window7_dir = '/mnt/aperto/yin/swinunetr_results/swinunetr_3D_pretrain_window7_downsample/' \n",
    "swin_3D_pretrain_window7_files = sorted(glob.glob(f'{swin_3D_pretrain_window7_dir}*_img_pred.pt'))\n",
    "swin_3D_pretrain_window7_predict = {}\n",
    "for item in swin_3D_pretrain_window7_files:\n",
    "    idx = item.split('/')[-1].split('_')[0]\n",
    "    swin_3D_pretrain_window7_predict[idx] = torch.load(item)['instance_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aa6e45-9813-4293-b7c9-8cf7ca10a917",
   "metadata": {},
   "source": [
    "#### load test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b2afefe9-47ef-4d3d-8104-21056bb7e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_file_path = './test_files.json'\n",
    "\n",
    "# read test json file\n",
    "with open(json_file_path) as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "# # filter norm test data\n",
    "test_files = [f for f in test_data if '*img.tif' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "89279043-2885-4a33-9259-fd1923db467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to recursively search for matching strings\n",
    "\n",
    "import json\n",
    "import fnmatch\n",
    "def find_matching_strings(obj, pattern):\n",
    "    matches = []\n",
    "    if isinstance(obj, dict):\n",
    "        for key, value in obj.items():\n",
    "            matches.extend(find_matching_strings(value, pattern))\n",
    "    elif isinstance(obj, list):\n",
    "        for item in obj:\n",
    "            matches.extend(find_matching_strings(item, pattern))\n",
    "    elif isinstance(obj, str):\n",
    "        if fnmatch.fnmatch(obj, pattern):\n",
    "            matches.append(obj)\n",
    "    return matches\n",
    "\n",
    "# Define the pattern to match\n",
    "pattern = '*img.tif'\n",
    "\n",
    "# Find all matching strings in the JSON data\n",
    "matching_strings = find_matching_strings(test_data, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bb2bc7e1-7336-4c2b-8fef-0e28a8620a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = [item.split('_')[0] for item in matching_strings]\n",
    "test_id = sorted(test_id, key=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eed629a-8f16-4261-ab76-d4cb6c390b66",
   "metadata": {},
   "source": [
    "#### load shuffled list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "022a487a-9f0c-42e7-ad41-2238f9ae80b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./shuffle_model.pkl', 'rb') as f:\n",
    "    shuffle_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bd485ad1-798c-4bd5-9ccd-e3ffa514d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rank_list = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "640f3233-f4b8-4415-bb80-60a97f982e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### img_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0098154-a9e6-4aa9-bf4a-e184de3138dc",
   "metadata": {},
   "source": [
    "#### napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e4d77651-9f40-4af1-8746-2f6471bfbec9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0168 with the position [1029, 6925, 4930]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to re-analyze the data? y or n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0172 with the position [1404, 3356, 4747]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in the rank of model 1,2,3,4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected and save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/3348005403.py:224: UserWarning: ./crops/0172_model1.tif is a low contrast image\n",
      "  io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:225: UserWarning: ./crops/0172_model2.tif is a low contrast image\n",
      "  io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:226: UserWarning: ./crops/0172_model3.tif is a low contrast image\n",
      "  io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:227: UserWarning: ./crops/0172_model4.tif is a low contrast image\n",
      "  io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0176 with the position [1527, 3192, 1478]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in the rank of model 2,3,1,4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected and save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/3348005403.py:224: UserWarning: ./crops/0176_model1.tif is a low contrast image\n",
      "  io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:225: UserWarning: ./crops/0176_model2.tif is a low contrast image\n",
      "  io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:226: UserWarning: ./crops/0176_model3.tif is a low contrast image\n",
      "  io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:227: UserWarning: ./crops/0176_model4.tif is a low contrast image\n",
      "  io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0177 with the position [1561, 1100, 1932]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in the rank of model 2,1,3,4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected and save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/3348005403.py:224: UserWarning: ./crops/0177_model1.tif is a low contrast image\n",
      "  io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:225: UserWarning: ./crops/0177_model2.tif is a low contrast image\n",
      "  io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:226: UserWarning: ./crops/0177_model3.tif is a low contrast image\n",
      "  io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:227: UserWarning: ./crops/0177_model4.tif is a low contrast image\n",
      "  io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0181 with the position [881, 2570, 5608]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in the rank of model 1,2,3,4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected and save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/3348005403.py:224: UserWarning: ./crops/0181_model1.tif is a low contrast image\n",
      "  io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:225: UserWarning: ./crops/0181_model2.tif is a low contrast image\n",
      "  io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:226: UserWarning: ./crops/0181_model3.tif is a low contrast image\n",
      "  io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:227: UserWarning: ./crops/0181_model4.tif is a low contrast image\n",
      "  io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0183 with the position [831, 739, 3776]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in the rank of model 1,2,3,4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected and save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/3348005403.py:224: UserWarning: ./crops/0183_model1.tif is a low contrast image\n",
      "  io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:225: UserWarning: ./crops/0183_model2.tif is a low contrast image\n",
      "  io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:226: UserWarning: ./crops/0183_model3.tif is a low contrast image\n",
      "  io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:227: UserWarning: ./crops/0183_model4.tif is a low contrast image\n",
      "  io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0202 with the position [1895, 5132, 1011]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in the rank of model 3,2,1,4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected and save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/3348005403.py:224: UserWarning: ./crops/0202_model1.tif is a low contrast image\n",
      "  io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:225: UserWarning: ./crops/0202_model2.tif is a low contrast image\n",
      "  io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:226: UserWarning: ./crops/0202_model3.tif is a low contrast image\n",
      "  io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:227: UserWarning: ./crops/0202_model4.tif is a low contrast image\n",
      "  io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0213 with the position [1277, 1599, 1145]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in the rank of model 1,2,3,4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected and save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/3348005403.py:224: UserWarning: ./crops/0213_model1.tif is a low contrast image\n",
      "  io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:225: UserWarning: ./crops/0213_model2.tif is a low contrast image\n",
      "  io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:226: UserWarning: ./crops/0213_model3.tif is a low contrast image\n",
      "  io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:227: UserWarning: ./crops/0213_model4.tif is a low contrast image\n",
      "  io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0221 with the position [1197, 3800, 4884]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in the rank of model 1,2,3,4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected and save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/3348005403.py:224: UserWarning: ./crops/0221_model1.tif is a low contrast image\n",
      "  io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:225: UserWarning: ./crops/0221_model2.tif is a low contrast image\n",
      "  io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:226: UserWarning: ./crops/0221_model3.tif is a low contrast image\n",
      "  io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:227: UserWarning: ./crops/0221_model4.tif is a low contrast image\n",
      "  io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0227 with the position [1074, 5892, 5460]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in the rank of model 1,2,3,4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected and save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/3348005403.py:224: UserWarning: ./crops/0227_model1.tif is a low contrast image\n",
      "  io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:225: UserWarning: ./crops/0227_model2.tif is a low contrast image\n",
      "  io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:226: UserWarning: ./crops/0227_model3.tif is a low contrast image\n",
      "  io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:227: UserWarning: ./crops/0227_model4.tif is a low contrast image\n",
      "  io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0231 with the position [943, 4331, 4980]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in the rank of model 2,3,4,1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected and save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/3348005403.py:224: UserWarning: ./crops/0231_model1.tif is a low contrast image\n",
      "  io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:225: UserWarning: ./crops/0231_model2.tif is a low contrast image\n",
      "  io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:226: UserWarning: ./crops/0231_model3.tif is a low contrast image\n",
      "  io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:227: UserWarning: ./crops/0231_model4.tif is a low contrast image\n",
      "  io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0238 with the position [1335, 4103, 5535]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in the rank of model 1,2,3,4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected and save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/3348005403.py:224: UserWarning: ./crops/0238_model1.tif is a low contrast image\n",
      "  io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:225: UserWarning: ./crops/0238_model2.tif is a low contrast image\n",
      "  io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:226: UserWarning: ./crops/0238_model3.tif is a low contrast image\n",
      "  io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:227: UserWarning: ./crops/0238_model4.tif is a low contrast image\n",
      "  io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0244 with the position [874, 2539, 1301]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in the rank of model 4,3,2,1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected and save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/3348005403.py:224: UserWarning: ./crops/0244_model1.tif is a low contrast image\n",
      "  io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:225: UserWarning: ./crops/0244_model2.tif is a low contrast image\n",
      "  io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:226: UserWarning: ./crops/0244_model3.tif is a low contrast image\n",
      "  io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:227: UserWarning: ./crops/0244_model4.tif is a low contrast image\n",
      "  io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0246 with the position [983, 7621, 2137]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in the rank of model 1,2,3,4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected and save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/3348005403.py:223: UserWarning: ./crops/0246_img.tif is a low contrast image\n",
      "  io.imsave(img_path, img, plugin='tifffile', imagej=True, metadata={'axes': 'CYX'})\n",
      "/tmp/ipykernel_287315/3348005403.py:224: UserWarning: ./crops/0246_model1.tif is a low contrast image\n",
      "  io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:225: UserWarning: ./crops/0246_model2.tif is a low contrast image\n",
      "  io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:226: UserWarning: ./crops/0246_model3.tif is a low contrast image\n",
      "  io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:227: UserWarning: ./crops/0246_model4.tif is a low contrast image\n",
      "  io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0260 with the position [1000, 3959, 987]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in the rank of model 2,3,4,1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected and save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/3348005403.py:224: UserWarning: ./crops/0260_model1.tif is a low contrast image\n",
      "  io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:225: UserWarning: ./crops/0260_model2.tif is a low contrast image\n",
      "  io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:226: UserWarning: ./crops/0260_model3.tif is a low contrast image\n",
      "  io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:227: UserWarning: ./crops/0260_model4.tif is a low contrast image\n",
      "  io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0269 with the position [1698, 6076, 2136]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in the rank of model 1,2,3,4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected and save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/3348005403.py:224: UserWarning: ./crops/0269_model1.tif is a low contrast image\n",
      "  io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:225: UserWarning: ./crops/0269_model2.tif is a low contrast image\n",
      "  io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:226: UserWarning: ./crops/0269_model3.tif is a low contrast image\n",
      "  io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:227: UserWarning: ./crops/0269_model4.tif is a low contrast image\n",
      "  io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0271 with the position [1257, 7096, 1954]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in the rank of model 2,3,4,1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected and save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/3348005403.py:224: UserWarning: ./crops/0271_model1.tif is a low contrast image\n",
      "  io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:225: UserWarning: ./crops/0271_model2.tif is a low contrast image\n",
      "  io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:226: UserWarning: ./crops/0271_model3.tif is a low contrast image\n",
      "  io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:227: UserWarning: ./crops/0271_model4.tif is a low contrast image\n",
      "  io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0274 with the position [716, 5718, 4326]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in the rank of model 2,3,4,1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected and save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/3348005403.py:224: UserWarning: ./crops/0274_model1.tif is a low contrast image\n",
      "  io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:225: UserWarning: ./crops/0274_model2.tif is a low contrast image\n",
      "  io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:226: UserWarning: ./crops/0274_model3.tif is a low contrast image\n",
      "  io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:227: UserWarning: ./crops/0274_model4.tif is a low contrast image\n",
      "  io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0275 with the position [1094, 4194, 1046]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in the rank of model 1,2,3,4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected and save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/3348005403.py:224: UserWarning: ./crops/0275_model1.tif is a low contrast image\n",
      "  io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:225: UserWarning: ./crops/0275_model2.tif is a low contrast image\n",
      "  io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:226: UserWarning: ./crops/0275_model3.tif is a low contrast image\n",
      "  io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:227: UserWarning: ./crops/0275_model4.tif is a low contrast image\n",
      "  io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0277 with the position [1187, 3292, 1448]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in the rank of model 1,2,3,4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected and save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/3348005403.py:223: UserWarning: ./crops/0277_img.tif is a low contrast image\n",
      "  io.imsave(img_path, img, plugin='tifffile', imagej=True, metadata={'axes': 'CYX'})\n",
      "/tmp/ipykernel_287315/3348005403.py:224: UserWarning: ./crops/0277_model1.tif is a low contrast image\n",
      "  io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:225: UserWarning: ./crops/0277_model2.tif is a low contrast image\n",
      "  io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:226: UserWarning: ./crops/0277_model3.tif is a low contrast image\n",
      "  io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:227: UserWarning: ./crops/0277_model4.tif is a low contrast image\n",
      "  io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0279 with the position [1153, 4636, 2866]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in the rank of model 2,3,4,1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected and save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/3348005403.py:224: UserWarning: ./crops/0279_model1.tif is a low contrast image\n",
      "  io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:225: UserWarning: ./crops/0279_model2.tif is a low contrast image\n",
      "  io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:226: UserWarning: ./crops/0279_model3.tif is a low contrast image\n",
      "  io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:227: UserWarning: ./crops/0279_model4.tif is a low contrast image\n",
      "  io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0281 with the position [1139, 5008, 3822]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in the rank of model 1,2,3,4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected and save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/3348005403.py:224: UserWarning: ./crops/0281_model1.tif is a low contrast image\n",
      "  io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:225: UserWarning: ./crops/0281_model2.tif is a low contrast image\n",
      "  io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:226: UserWarning: ./crops/0281_model3.tif is a low contrast image\n",
      "  io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:227: UserWarning: ./crops/0281_model4.tif is a low contrast image\n",
      "  io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0282 with the position [1164, 5110, 3803]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in the rank of model 2,3,4,1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected and save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/3348005403.py:224: UserWarning: ./crops/0282_model1.tif is a low contrast image\n",
      "  io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:225: UserWarning: ./crops/0282_model2.tif is a low contrast image\n",
      "  io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:226: UserWarning: ./crops/0282_model3.tif is a low contrast image\n",
      "  io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:227: UserWarning: ./crops/0282_model4.tif is a low contrast image\n",
      "  io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0285 with the position [1639, 7418, 3041]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type in the rank of model 2,3,4,1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected and save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/3348005403.py:224: UserWarning: ./crops/0285_model1.tif is a low contrast image\n",
      "  io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:225: UserWarning: ./crops/0285_model2.tif is a low contrast image\n",
      "  io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:226: UserWarning: ./crops/0285_model3.tif is a low contrast image\n",
      "  io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
      "/tmp/ipykernel_287315/3348005403.py:227: UserWarning: ./crops/0285_model4.tif is a low contrast image\n",
      "  io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n"
     ]
    }
   ],
   "source": [
    "for ori_id in test_id[35:]:\n",
    "    ori_corner_position = [ori_data['corner'][int(ori_id)]]\n",
    "    ori_plane = int(ori_data['plane_position'][int(ori_id)])\n",
    "    segment_chan = int(ori_data['channel'][int(ori_id)])\n",
    "    reference_chan =  int(ori_data['ref_channel'][int(ori_id)])\n",
    "    #check which source it should be int 0 or 1\n",
    "    brain_source = int(ori_data['source'][int(ori_id)].split('/')[-3].split('_')[-2][0])-1\n",
    "    ##########\n",
    "    ## add cellpose prediction\n",
    "    try:\n",
    "        cellpose_predict = cellpose_data[ori_id]\n",
    "    except:\n",
    "        print(f'this id {ori_id} is exceed original id range, continue')\n",
    "        continue\n",
    "    model_id = shuffle_model[ori_id]\n",
    "    \n",
    "    # expand cellpose_prediction to correct size\n",
    "    # create a 256x256 array of zeros\n",
    "    single_layer = np.zeros((768, 768))\n",
    "    # stack this array 100 times along a new axis (axis=0)\n",
    "    data1 = np.stack([single_layer] * 100, axis=0)\n",
    "    expanded_array = np.zeros((768, 768))\n",
    "    # Calculate the starting indices to place the 256x256 array in the center\n",
    "    start_index = (768 - 256) // 2\n",
    "    # Place the 256x256 array in the center of the 768x768 array\n",
    "    expanded_array[start_index:start_index+256, start_index:start_index+256] = cellpose_predict\n",
    "    data1[ori_plane] = expanded_array\n",
    "    data1 = data1.astype(int)\n",
    "\n",
    "\n",
    "    # create a 256x256 array of zeros\n",
    "    single_layer = np.zeros((768, 768))\n",
    "    # stack this array 100 times along a new axis (axis=0)\n",
    "    data2 = np.stack([single_layer] * 100, axis=0)\n",
    "    expanded_array = np.zeros((768, 768))\n",
    "    # Calculate the starting indices to place the 256x256 array in the center\n",
    "    start_index = (768 - 256) // 2\n",
    "    # Place the 256x256 array in the center of the 768x768 array\n",
    "    expanded_array[start_index:start_index+256, start_index:start_index+256] = stardist_data[ori_id]\n",
    "    data2[ori_plane] = expanded_array\n",
    "    data2 = data2.astype(int)\n",
    "\n",
    "\n",
    "    # create a 256x256 array of zeros\n",
    "    single_layer = np.zeros((768, 768))\n",
    "    # stack this array 100 times along a new axis (axis=0)\n",
    "    data3 = np.stack([single_layer] * 100, axis=0)\n",
    "    expanded_array = np.zeros((768, 768))\n",
    "    # Calculate the starting indices to place the 256x256 array in the center\n",
    "    start_index = (768 - 256) // 2\n",
    "    # Place the 256x256 array in the center of the 768x768 array\n",
    "    expanded_array[start_index:start_index+256, start_index:start_index+256] = swin2d_predict[ori_id]\n",
    "    data3[ori_plane] = expanded_array\n",
    "    data3 = data3.astype(int)\n",
    "\n",
    "\n",
    "    # create a 256x256 array of zeros\n",
    "    single_layer = np.zeros((768, 768))\n",
    "    # stack this array 100 times along a new axis (axis=0)\n",
    "    data4 = np.stack([single_layer] * 100, axis=0)\n",
    "    expanded_array = np.zeros((768, 768))\n",
    "    # Calculate the starting indices to place the 256x256 array in the center\n",
    "    start_index = (768 - 256) // 2\n",
    "    # Place the 256x256 array in the center of the 768x768 array\n",
    "    expanded_array[start_index:start_index+256, start_index:start_index+256] = swin_3D_pretrain_window3_predict[ori_id]\n",
    "    data4[ori_plane] = expanded_array\n",
    "    data4 = data4.astype(int)\n",
    "\n",
    "    \n",
    "    data_map = {\n",
    "        1: data1,\n",
    "        2: data2,\n",
    "        3: data3,\n",
    "    }\n",
    "    \n",
    "    class1_data = data_map.get( model_id[0], data4)     \n",
    "    class2_data = data_map.get( model_id[1], data4)\n",
    "    class3_data = data_map.get( model_id[2], data4)     \n",
    "    class4_data = data_map.get( model_id[3], data4)     \n",
    "    \n",
    "    pos = ori_corner_position[0]\n",
    "    if len(pos) <= 2:\n",
    "        raise ValueError('The position should have length 3')\n",
    "    elif len(pos) == 3:\n",
    "        isHard = 0\n",
    "    elif len(pos) == 4:\n",
    "        isHard = pos[-1]\n",
    "        pos = pos[:-1]\n",
    "    else:\n",
    "        raise ValueError('You have a wrong position format')\n",
    "        \n",
    "    print(f\"The index {ori_id} with the position {pos}\")\n",
    "    idx = int(ori_id)\n",
    "    \n",
    "    # find out any duplication between the current data and the metadata\n",
    "    # if it is duplicated, ask \n",
    "    flag = False\n",
    "    if df['corner'].isin([pos]).any():\n",
    "        for k in df['integer_ID'][df['corner'].isin([pos])].to_list():\n",
    "            if ((df.loc[k,'source'] == fix_n5_path[brain_source]) and \n",
    "                (df.loc[k,'ref_channel'] == reference_chan) and \n",
    "                (df.loc[k,'channel'] == segment_chan) and \n",
    "                (df.loc[k,'crop_size'] == crop_size) and\n",
    "                (df.loc[k,'select_plane'] == select_plane)):\n",
    "                flag = True\n",
    "                idx = k\n",
    "    \n",
    "    if flag:\n",
    "        ans = input(\"Do you want to re-analyze the data? y or n\")\n",
    "        if ans != 'y':\n",
    "            continue\n",
    "        \n",
    "    # set file path to be saved for both image and mask\n",
    "    prefix = str(idx)\n",
    "    while len(prefix) < 4:\n",
    "        prefix = '0' + prefix\n",
    "    img_path = os.path.join(save_path, prefix+'_img.tif')\n",
    "    mask_path = [os.path.join(save_path, prefix+'_model1.tif')\n",
    "                ,os.path.join(save_path, prefix+'_model2.tif')\n",
    "                ,os.path.join(save_path, prefix+'_model3.tif')\n",
    "                ,os.path.join(save_path, prefix+'_model4.tif')]\n",
    "\n",
    "    #### get which sources\n",
    "\n",
    "    # get the image of a channel to be segmented\n",
    "    FoV_stack = []\n",
    "    img = fix_zarr[brain_source][n5_setups[segment_chan]]['timepoint0']['s0']\n",
    "\n",
    "    # set the corner of FoV in napari\n",
    "    top_corner = tuple(i-(k-j)//2 for i,j,k in zip(pos, crop_size, FoV))\n",
    "    bottom_corner = tuple(i+j+(k-j)//2 for i,j,k in zip(pos, crop_size, FoV))\n",
    "    top_corner = tuple(j if j>=i else i for i,j in zip([0,0,0],top_corner))\n",
    "    bottom_corner = tuple(j if j<=i else i for i,j in zip(img.shape,bottom_corner))\n",
    "    \n",
    "    # prepare to make border lines\n",
    "    top_border_corner = tuple((k-j)//2 for j,k in zip(crop_size, FoV))\n",
    "    bottom_border_corner = tuple(j+(k-j)//2 for j,k in zip(crop_size, FoV))\n",
    "    \n",
    "    FoV_segment = img[tuple(slice(i,j) for i,j in zip(top_corner, bottom_corner))]\n",
    "\n",
    "    # get the image of a reference of channel\n",
    "    if reference_chan is not None:\n",
    "        img = fix_zarr[brain_source][n5_setups[reference_chan]]['timepoint0']['s0']\n",
    "        FoV_reference = img[tuple(slice(i,j) for i,j in zip(top_corner, bottom_corner))]\n",
    "        FoV_stack.append(FoV_reference)\n",
    "    \n",
    "    FoV_stack.append(FoV_segment)\n",
    "    FoV_stack = np.stack(FoV_stack)\n",
    "\n",
    "    ##### FoV is a 2channel(reference and signal) Field of view\n",
    "    # open Napari. Pause for loop until close the window\n",
    "    viewer = napari.Viewer()\n",
    "    # set hotkey\n",
    "     # set quit key\n",
    "    @viewer.bind_key('q')\n",
    "    def close_viewer(viewer):\n",
    "        print(\"Closing viewer...\")\n",
    "        viewer.close()\n",
    "\n",
    "     #set hide hotkey\n",
    "    @viewer.bind_key('h')\n",
    "    def toggle_layer_visibility(viewer):\n",
    "        layer = viewer.layers.selection.active\n",
    "        if layer is not None:\n",
    "            layer.visible = not layer.visible\n",
    "    \n",
    "    viewer.add_image(FoV_stack, channel_axis=0, scale=voxel_size, contrast_limits=[0,65535])\n",
    "    viewer.add_shapes([[bottom_border_corner[1]*voxel_size[1],bottom_border_corner[2]*voxel_size[2]],[top_border_corner[1]*voxel_size[1],bottom_border_corner[2]*voxel_size[2]]],\n",
    "                      edge_width=2,edge_color='white',ndim=2,shape_type='line')\n",
    "    viewer.add_shapes([[top_border_corner[1]*voxel_size[1],bottom_border_corner[2]*voxel_size[2]],[top_border_corner[1]*voxel_size[1],top_border_corner[2]*voxel_size[2]]],\n",
    "                  edge_width=2,edge_color='white',ndim=2,shape_type='line')\n",
    "    viewer.add_shapes([[bottom_border_corner[1]*voxel_size[1],bottom_border_corner[2]*voxel_size[2]],[bottom_border_corner[1]*voxel_size[1],top_border_corner[2]*voxel_size[2]]],\n",
    "                  edge_width=2,edge_color='white',ndim=2,shape_type='line')\n",
    "    viewer.add_shapes([[bottom_border_corner[1]*voxel_size[1],top_border_corner[2]*voxel_size[2]],[top_border_corner[1]*voxel_size[1],top_border_corner[2]*voxel_size[2]]],\n",
    "                  edge_width=2,edge_color='white',ndim=2,shape_type='line')\n",
    "    \n",
    "    #labels = viewer.add_labels(np.zeros_like(FoV_segment), name='segmentation', scale=voxel_size)\n",
    "    #add three classes label layers\n",
    "    labels_class1 = viewer.add_labels(class1_data,  name=f'model1({ori_plane})', scale=voxel_size)\n",
    "    labels_class1.opacity = 1.0\n",
    "    labels_class2 = viewer.add_labels(class2_data,  name=f'model2({ori_plane})', scale=voxel_size)\n",
    "    labels_class2.opacity = 1.0\n",
    "    labels_class3 = viewer.add_labels(class3_data,  name=f'model3({ori_plane})', scale=voxel_size)\n",
    "    labels_class3.opacity = 1.0\n",
    "    labels_class4 = viewer.add_labels(class4_data,  name=f'model4({ori_plane})', scale=voxel_size)\n",
    "    labels_class4.opacity = 1.0\n",
    "    \n",
    "    viewer.camera.zoom = 1.5\n",
    "    \n",
    "    viewer.dims.current_step = (ori_plane,400,400)\n",
    "    viewer.show(block=True)\n",
    "    model_rank = input(\"Please type in the rank of model\")\n",
    "    model_rank_list[ori_id]= model_rank\n",
    "    comment = input(\"Do you have any comments when ranking the model?\")\n",
    "\n",
    "    \n",
    "    sub_area_slicer = tuple(slice(i,j) for i,j in zip(top_border_corner,bottom_border_corner))\n",
    "    ######\n",
    "    # subarea shape\n",
    "    # save images and segmentation.\n",
    "    img = np.swapaxes(FoV_stack[(slice(0,None),)+sub_area_slicer],0,1)\n",
    "    ######\n",
    "    # modify this to cellpose label\n",
    "    #labels_img = labels.data[sub_area_slicer]\n",
    "    labels_img_class1 = labels_class1.data[sub_area_slicer]\n",
    "    labels_img_class2 = labels_class2.data[sub_area_slicer]\n",
    "    labels_img_class3 = labels_class3.data[sub_area_slicer]\n",
    "    labels_img_class4 = labels_class4.data[sub_area_slicer]\n",
    "\n",
    "   \n",
    "    if select_plane:\n",
    "        print('selected and save')\n",
    "        ##########\n",
    "        # modify this to original label\n",
    "        plane_pos = np.argmax((labels_class1.data>0).sum(axis=(1,2)))\n",
    "        img = img[plane_pos,...]\n",
    "        labels_img_class1 = labels_img_class1[plane_pos,...]\n",
    "        labels_img_class2 = labels_img_class2[plane_pos,...]\n",
    "        labels_img_class3 = labels_img_class3[plane_pos,...]\n",
    "        labels_img_class4 = labels_img_class4[plane_pos,...]\n",
    "        \n",
    "        io.imsave(img_path, img, plugin='tifffile', imagej=True, metadata={'axes': 'CYX'})\n",
    "        io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
    "        io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
    "        io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
    "        io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n",
    "\n",
    "    else:\n",
    "        print('#############')\n",
    "        print('not selected and save')\n",
    "        io.imsave(img_path, img, plugin='tifffile', imagej=True, metadata={'axes': 'ZCYX'})\n",
    "        io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
    "        io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
    "        io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
    "    # update the metadata\n",
    "    df.loc[idx,'ID'] = prefix\n",
    "    df.loc[idx,'integer_ID'] = idx\n",
    "    count = (np.unique(labels_img_class1)).size - 1\n",
    "    df.loc[idx,'instance_counts'] = count\n",
    "    df.at[idx,'corner'] = pos\n",
    "    df.loc[idx, 'source'] = fix_n5_path[brain_source]\n",
    "    df.loc[idx, 'ref_channel'] = reference_chan\n",
    "    df.loc[idx, 'channel'] = segment_chan\n",
    "    df.at[idx, 'crop_size'] = crop_size\n",
    "    df.loc[idx, 'select_plane'] = select_plane\n",
    "    df.loc[idx, 'isHard'] = isHard\n",
    "    df.loc[idx, 'model_rank'] = model_rank\n",
    "    df.loc[idx, 'comments'] = comment\n",
    "    \n",
    "    if select_plane:\n",
    "        df.loc[idx, 'plane_position'] = int(plane_pos)\n",
    "    else:\n",
    "        df.loc[idx, 'plane_position'] = -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cb89b64b-866a-4a64-9ad5-ad978ddddb65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0168': '1,2,3,4',\n",
       " '0172': '1,2,3,4',\n",
       " '0176': '2,3,1,4',\n",
       " '0177': '2,1,3,4',\n",
       " '0181': '1,2,3,4',\n",
       " '0183': '1,2,3,4',\n",
       " '0202': '3,2,1,4',\n",
       " '0213': '1,2,3,4',\n",
       " '0221': '1,2,3,4',\n",
       " '0227': '1,2,3,4',\n",
       " '0231': '2,3,4,1',\n",
       " '0238': '1,2,3,4',\n",
       " '0244': '4,3,2,1',\n",
       " '0246': '1,2,3,4',\n",
       " '0260': '2,3,4,1',\n",
       " '0269': '1,2,3,4',\n",
       " '0271': '2,3,4,1',\n",
       " '0274': '2,3,4,1',\n",
       " '0275': '1,2,3,4',\n",
       " '0277': '1,2,3,4',\n",
       " '0279': '2,3,4,1',\n",
       " '0281': '1,2,3,4',\n",
       " '0282': '2,3,4,1',\n",
       " '0285': '2,3,4,1'}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rank_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8d5daaeb-0054-4030-b428-93e4415da6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>integer_ID</th>\n",
       "      <th>instance_counts</th>\n",
       "      <th>corner</th>\n",
       "      <th>source</th>\n",
       "      <th>ref_channel</th>\n",
       "      <th>channel</th>\n",
       "      <th>crop_size</th>\n",
       "      <th>isHard</th>\n",
       "      <th>plane_position</th>\n",
       "      <th>best_model</th>\n",
       "      <th>select_plane</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0168</td>\n",
       "      <td>168</td>\n",
       "      <td>235</td>\n",
       "      <td>[1029, 6925, 4930]</td>\n",
       "      <td>/mnt/aperto/Tatz_brain_data/fused/fused.n5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[100, 256, 256]</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>1,2,3,4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0172</td>\n",
       "      <td>172</td>\n",
       "      <td>108</td>\n",
       "      <td>[1404, 3356, 4747]</td>\n",
       "      <td>/mnt/aperto/Tatz_brain_data/fused/fused.n5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[100, 256, 256]</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>1,2,3,4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0176</td>\n",
       "      <td>176</td>\n",
       "      <td>27</td>\n",
       "      <td>[1527, 3192, 1478]</td>\n",
       "      <td>/mnt/aperto/Tatz_brain_data/fused/fused.n5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[100, 256, 256]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2,3,1,4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0177</td>\n",
       "      <td>177</td>\n",
       "      <td>27</td>\n",
       "      <td>[1561, 1100, 1932]</td>\n",
       "      <td>/mnt/aperto/Tatz_brain_data/fused/fused.n5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[100, 256, 256]</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>2,1,3,4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0181</td>\n",
       "      <td>181</td>\n",
       "      <td>11</td>\n",
       "      <td>[881, 2570, 5608]</td>\n",
       "      <td>/mnt/aperto/Tatz_brain_data/fused/fused.n5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[100, 256, 256]</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>1,2,3,4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0183</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>[831, 739, 3776]</td>\n",
       "      <td>/mnt/aperto/Tatz_brain_data/fused/fused.n5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[100, 256, 256]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,2,3,4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0202</td>\n",
       "      <td>202</td>\n",
       "      <td>80</td>\n",
       "      <td>[1895, 5132, 1011]</td>\n",
       "      <td>/mnt/aperto/Tatz_brain_data/fused/fused.n5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[100, 256, 256]</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3,2,1,4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0213</td>\n",
       "      <td>213</td>\n",
       "      <td>39</td>\n",
       "      <td>[1277, 1599, 1145]</td>\n",
       "      <td>/mnt/aperto/Tatz_brain_data/fused/fused.n5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[100, 256, 256]</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>1,2,3,4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0221</td>\n",
       "      <td>221</td>\n",
       "      <td>96</td>\n",
       "      <td>[1197, 3800, 4884]</td>\n",
       "      <td>/mnt/aperto/Tatz_brain_data/fused/fused.n5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[100, 256, 256]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1,2,3,4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0227</td>\n",
       "      <td>227</td>\n",
       "      <td>17</td>\n",
       "      <td>[1074, 5892, 5460]</td>\n",
       "      <td>/mnt/aperto/Tatz_brain_data/fused/fused.n5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[100, 256, 256]</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1,2,3,4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0231</td>\n",
       "      <td>231</td>\n",
       "      <td>7</td>\n",
       "      <td>[943, 4331, 4980]</td>\n",
       "      <td>/mnt/aperto/Tatz_brain_data/fused/fused.n5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[100, 256, 256]</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>2,3,4,1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0238</td>\n",
       "      <td>238</td>\n",
       "      <td>26</td>\n",
       "      <td>[1335, 4103, 5535]</td>\n",
       "      <td>/mnt/aperto/Tatz_brain_data/fused/fused.n5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[100, 256, 256]</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1,2,3,4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0244</td>\n",
       "      <td>244</td>\n",
       "      <td>42</td>\n",
       "      <td>[874, 2539, 1301]</td>\n",
       "      <td>/mnt/aperto/Tatz_brain_data/fused/fused.n5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[100, 256, 256]</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>4,3,2,1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0246</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>[983, 7621, 2137]</td>\n",
       "      <td>/mnt/aperto/Tatz_brain_data/fused/fused.n5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[100, 256, 256]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,2,3,4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0260</td>\n",
       "      <td>260</td>\n",
       "      <td>51</td>\n",
       "      <td>[1000, 3959, 987]</td>\n",
       "      <td>/mnt/aperto/fused/fused.n5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[100, 256, 256]</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>2,3,4,1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0269</td>\n",
       "      <td>269</td>\n",
       "      <td>25</td>\n",
       "      <td>[1698, 6076, 2136]</td>\n",
       "      <td>/mnt/aperto/fused/fused.n5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[100, 256, 256]</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1,2,3,4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0271</td>\n",
       "      <td>271</td>\n",
       "      <td>236</td>\n",
       "      <td>[1257, 7096, 1954]</td>\n",
       "      <td>/mnt/aperto/Tatz_brain_data/fused/fused.n5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[100, 256, 256]</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>2,3,4,1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0274</td>\n",
       "      <td>274</td>\n",
       "      <td>43</td>\n",
       "      <td>[716, 5718, 4326]</td>\n",
       "      <td>/mnt/aperto/Tatz_brain_data/fused/fused.n5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[100, 256, 256]</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>2,3,4,1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0275</td>\n",
       "      <td>275</td>\n",
       "      <td>17</td>\n",
       "      <td>[1094, 4194, 1046]</td>\n",
       "      <td>/mnt/aperto/fused/fused.n5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[100, 256, 256]</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1,2,3,4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0277</td>\n",
       "      <td>277</td>\n",
       "      <td>102</td>\n",
       "      <td>[1187, 3292, 1448]</td>\n",
       "      <td>/mnt/aperto/fused/fused.n5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[100, 256, 256]</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>1,2,3,4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0279</td>\n",
       "      <td>279</td>\n",
       "      <td>57</td>\n",
       "      <td>[1153, 4636, 2866]</td>\n",
       "      <td>/mnt/aperto/fused/fused.n5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[100, 256, 256]</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>2,3,4,1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0281</td>\n",
       "      <td>281</td>\n",
       "      <td>30</td>\n",
       "      <td>[1139, 5008, 3822]</td>\n",
       "      <td>/mnt/aperto/fused/fused.n5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[100, 256, 256]</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>1,2,3,4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0282</td>\n",
       "      <td>282</td>\n",
       "      <td>19</td>\n",
       "      <td>[1164, 5110, 3803]</td>\n",
       "      <td>/mnt/aperto/fused/fused.n5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[100, 256, 256]</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>2,3,4,1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0285</td>\n",
       "      <td>285</td>\n",
       "      <td>58</td>\n",
       "      <td>[1639, 7418, 3041]</td>\n",
       "      <td>/mnt/aperto/fused/fused.n5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[100, 256, 256]</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>2,3,4,1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID integer_ID instance_counts              corner  \\\n",
       "168  0168        168             235  [1029, 6925, 4930]   \n",
       "172  0172        172             108  [1404, 3356, 4747]   \n",
       "176  0176        176              27  [1527, 3192, 1478]   \n",
       "177  0177        177              27  [1561, 1100, 1932]   \n",
       "181  0181        181              11   [881, 2570, 5608]   \n",
       "183  0183        183               0    [831, 739, 3776]   \n",
       "202  0202        202              80  [1895, 5132, 1011]   \n",
       "213  0213        213              39  [1277, 1599, 1145]   \n",
       "221  0221        221              96  [1197, 3800, 4884]   \n",
       "227  0227        227              17  [1074, 5892, 5460]   \n",
       "231  0231        231               7   [943, 4331, 4980]   \n",
       "238  0238        238              26  [1335, 4103, 5535]   \n",
       "244  0244        244              42   [874, 2539, 1301]   \n",
       "246  0246        246               0   [983, 7621, 2137]   \n",
       "260  0260        260              51   [1000, 3959, 987]   \n",
       "269  0269        269              25  [1698, 6076, 2136]   \n",
       "271  0271        271             236  [1257, 7096, 1954]   \n",
       "274  0274        274              43   [716, 5718, 4326]   \n",
       "275  0275        275              17  [1094, 4194, 1046]   \n",
       "277  0277        277             102  [1187, 3292, 1448]   \n",
       "279  0279        279              57  [1153, 4636, 2866]   \n",
       "281  0281        281              30  [1139, 5008, 3822]   \n",
       "282  0282        282              19  [1164, 5110, 3803]   \n",
       "285  0285        285              58  [1639, 7418, 3041]   \n",
       "\n",
       "                                         source ref_channel channel  \\\n",
       "168  /mnt/aperto/Tatz_brain_data/fused/fused.n5           3       4   \n",
       "172  /mnt/aperto/Tatz_brain_data/fused/fused.n5           3       4   \n",
       "176  /mnt/aperto/Tatz_brain_data/fused/fused.n5           3       4   \n",
       "177  /mnt/aperto/Tatz_brain_data/fused/fused.n5           3       4   \n",
       "181  /mnt/aperto/Tatz_brain_data/fused/fused.n5           3       4   \n",
       "183  /mnt/aperto/Tatz_brain_data/fused/fused.n5           3       4   \n",
       "202  /mnt/aperto/Tatz_brain_data/fused/fused.n5           3       2   \n",
       "213  /mnt/aperto/Tatz_brain_data/fused/fused.n5           3       2   \n",
       "221  /mnt/aperto/Tatz_brain_data/fused/fused.n5           3       2   \n",
       "227  /mnt/aperto/Tatz_brain_data/fused/fused.n5           3       4   \n",
       "231  /mnt/aperto/Tatz_brain_data/fused/fused.n5           3       4   \n",
       "238  /mnt/aperto/Tatz_brain_data/fused/fused.n5           3       2   \n",
       "244  /mnt/aperto/Tatz_brain_data/fused/fused.n5           3       2   \n",
       "246  /mnt/aperto/Tatz_brain_data/fused/fused.n5           3       2   \n",
       "260                  /mnt/aperto/fused/fused.n5           3       4   \n",
       "269                  /mnt/aperto/fused/fused.n5           3       1   \n",
       "271  /mnt/aperto/Tatz_brain_data/fused/fused.n5           3       2   \n",
       "274  /mnt/aperto/Tatz_brain_data/fused/fused.n5           3       2   \n",
       "275                  /mnt/aperto/fused/fused.n5           3       4   \n",
       "277                  /mnt/aperto/fused/fused.n5           3       4   \n",
       "279                  /mnt/aperto/fused/fused.n5           3       4   \n",
       "281                  /mnt/aperto/fused/fused.n5           3       1   \n",
       "282                  /mnt/aperto/fused/fused.n5           3       1   \n",
       "285                  /mnt/aperto/fused/fused.n5           3       1   \n",
       "\n",
       "           crop_size isHard plane_position best_model select_plane  \n",
       "168  [100, 256, 256]      0             97    1,2,3,4         True  \n",
       "172  [100, 256, 256]      0             49    1,2,3,4         True  \n",
       "176  [100, 256, 256]      0              0    2,3,1,4         True  \n",
       "177  [100, 256, 256]      0             49    2,1,3,4         True  \n",
       "181  [100, 256, 256]      0             49    1,2,3,4         True  \n",
       "183  [100, 256, 256]      0              0    1,2,3,4         True  \n",
       "202  [100, 256, 256]      0             17    3,2,1,4         True  \n",
       "213  [100, 256, 256]      0             49    1,2,3,4         True  \n",
       "221  [100, 256, 256]      0              1    1,2,3,4         True  \n",
       "227  [100, 256, 256]      0             16    1,2,3,4         True  \n",
       "231  [100, 256, 256]      0             34    2,3,4,1         True  \n",
       "238  [100, 256, 256]      0             19    1,2,3,4         True  \n",
       "244  [100, 256, 256]      0             63    4,3,2,1         True  \n",
       "246  [100, 256, 256]      0              0    1,2,3,4         True  \n",
       "260  [100, 256, 256]      0             38    2,3,4,1         True  \n",
       "269  [100, 256, 256]      0             44    1,2,3,4         True  \n",
       "271  [100, 256, 256]      0             49    2,3,4,1         True  \n",
       "274  [100, 256, 256]      0             49    2,3,4,1         True  \n",
       "275  [100, 256, 256]      0             41    1,2,3,4         True  \n",
       "277  [100, 256, 256]      0             49    1,2,3,4         True  \n",
       "279  [100, 256, 256]      0             49    2,3,4,1         True  \n",
       "281  [100, 256, 256]      0             49    1,2,3,4         True  \n",
       "282  [100, 256, 256]      0             45    2,3,4,1         True  \n",
       "285  [100, 256, 256]      0             49    2,3,4,1         True  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4ff5b42e-e22b-496d-8eb0-9d3109480c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the file through pickle the metadata\n",
    "df.to_pickle(meta_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ac7e2f-877d-4cc4-afa7-33d5ca775750",
   "metadata": {},
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ff329081-757d-4f92-a015-166f47cb9601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current image id 285, next begin id 285\n"
     ]
    }
   ],
   "source": [
    "# if you don't want to run all again, set the beginning id as begin\n",
    "curent_id = img_id.index(ori_id)\n",
    "begin_id = curent_id\n",
    "print(f'current image id {curent_id}, next begin id {begin_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d3d4bdb5-da67-404a-9dc1-db072ef554b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional)if you want to start all over again, reset begin_id as 0\n",
    "# begin_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53faee0b-9ee2-44e0-ad5e-f969d6c49c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
