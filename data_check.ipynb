{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f50bd344-395a-4d5e-b294-c741e43a8104",
   "metadata": {},
   "source": [
    "#### load test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e41d613f-c924-4c26-830f-fd9b63159a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_file_path = './test_files.json'\n",
    "\n",
    "# read test json file\n",
    "with open(json_file_path) as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "# # filter norm test data\n",
    "test_files = [f for f in test_data if '*img.tif' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6427dff-1043-4348-a44d-9da92145c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to recursively search for matching strings\n",
    "\n",
    "import json\n",
    "import fnmatch\n",
    "def find_matching_strings(obj, pattern):\n",
    "    matches = []\n",
    "    if isinstance(obj, dict):\n",
    "        for key, value in obj.items():\n",
    "            matches.extend(find_matching_strings(value, pattern))\n",
    "    elif isinstance(obj, list):\n",
    "        for item in obj:\n",
    "            matches.extend(find_matching_strings(item, pattern))\n",
    "    elif isinstance(obj, str):\n",
    "        if fnmatch.fnmatch(obj, pattern):\n",
    "            matches.append(obj)\n",
    "    return matches\n",
    "\n",
    "# Define the pattern to match\n",
    "pattern = '*img.tif'\n",
    "\n",
    "# Find all matching strings in the JSON data\n",
    "matching_strings = find_matching_strings(test_data, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a65c803-4b14-45ce-be36-62f8e6bdd7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = [item.split('_')[0] for item in matching_strings]\n",
    "test_id = sorted(test_id, key=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b15a69f-7efc-45ab-bea6-3e80d0335f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./shuffle_model.pkl', 'rb') as f:\n",
    "    shuffle_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f516625-b180-495c-ad9d-307540e8205a",
   "metadata": {},
   "source": [
    "#### Check whether the saved image aligns with original image shuffle order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec9644c3-d1b8-422b-b463-2b75a6a5533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to change path to your pkl path\n",
    "with open('./cellpose_nonorm_all.pkl', 'rb') as f:\n",
    "    cellpose_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c23ab98-f8ef-4ce6-9557-63a0a02d90df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./stardist_all.pkl', 'rb') as f:\n",
    "    stardist_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fff52e5d-f5fa-41aa-bb5d-db1b2e4f9da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_421104/2055031262.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  swin2d_predict[idx] = torch.load(item)['instance_mask']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import glob\n",
    "### swinunetr_2D\n",
    "swin2d_dir = '/mnt/aperto/yin/swinunetr_results/swinunetr_2D/' \n",
    "swin2d_files = sorted(glob.glob(f'{swin2d_dir}*_img_pred.pt'))\n",
    "swin2d_predict = {}\n",
    "for item in swin2d_files:\n",
    "    idx = item.split('/')[-1].split('_')[0]\n",
    "    swin2d_predict[idx] = torch.load(item)['instance_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fd27359-cada-43ef-bd6a-4c18aa307570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_421104/750914079.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  swin_3D_pretrain_window3_predict[idx] = torch.load(item)['instance_mask']\n"
     ]
    }
   ],
   "source": [
    "### swinunetr_3D_window3\n",
    "swin_3D_pretrain_window3_dir = '/mnt/aperto/yin/swinunetr_results/swinunetr_3D_pretrain_window3/' \n",
    "swin_3D_pretrain_window3_files = sorted(glob.glob(f'{swin_3D_pretrain_window3_dir}*_img_pred.pt'))\n",
    "swin_3D_pretrain_window3_predict = {}\n",
    "for item in swin_3D_pretrain_window3_files:\n",
    "    idx = item.split('/')[-1].split('_')[0]\n",
    "    swin_3D_pretrain_window3_predict[idx] = torch.load(item)['instance_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbd96fea-95fa-4631-86f2-0ca4b00c7a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_map = {\n",
    "    1:cellpose_data,\n",
    "    2:stardist_data,\n",
    "    3:swin2d_predict,\n",
    "    4:swin_3D_pretrain_window3_predict\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d2a43cf-1838-4491-9745-9bf3c92411b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0005 same\n",
      "0006 same\n",
      "0009 same\n",
      "0017 same\n",
      "0022 same\n",
      "0024 same\n",
      "0030 same\n",
      "0033 same\n",
      "0042 same\n",
      "0045 same\n",
      "0046 same\n",
      "0056 same\n",
      "0059 same\n",
      "0060 same\n",
      "0063 same\n",
      "0066 same\n",
      "0075 same\n",
      "0077 same\n",
      "0079 same\n",
      "0084 same\n",
      "0090 same\n",
      "0101 same\n",
      "0109 same\n",
      "0113 same\n",
      "0117 same\n",
      "0118 same\n",
      "0119 same\n",
      "0124 same\n",
      "0125 same\n",
      "0143 same\n",
      "0146 same\n",
      "0147 same\n",
      "0158 same\n",
      "0159 same\n",
      "0165 same\n",
      "0168 same\n",
      "0172 same\n",
      "0176 same\n",
      "0177 same\n",
      "0181 same\n",
      "0183 same\n",
      "0202 same\n",
      "0213 same\n",
      "0221 same\n",
      "0227 same\n",
      "0231 same\n",
      "0238 same\n",
      "0244 same\n",
      "0246 same\n",
      "0260 same\n",
      "0269 same\n",
      "0271 same\n",
      "0274 same\n",
      "0275 same\n",
      "0277 same\n",
      "0279 same\n",
      "0281 same\n",
      "0282 same\n",
      "0285 same\n"
     ]
    }
   ],
   "source": [
    "import tiffile as tf\n",
    "import numpy as np\n",
    "for img_id in test_id:\n",
    "    model1_img = tf.imread(f'./crops/{img_id}_model1.tif')\n",
    "    model2_img = tf.imread(f'./crops/{img_id}_model2.tif')\n",
    "    model3_img = tf.imread(f'./crops/{img_id}_model3.tif')\n",
    "    model4_img = tf.imread(f'./crops/{img_id}_model4.tif')\n",
    "    model_ori1 = models_map[shuffle_model[img_id][0]][img_id]\n",
    "    model_ori2 = models_map[shuffle_model[img_id][1]][img_id]\n",
    "    model_ori3 = models_map[shuffle_model[img_id][2]][img_id]\n",
    "    model_ori4 = models_map[shuffle_model[img_id][3]][img_id]\n",
    "    are_equal1 = np.array_equal(model1_img, model_ori1)\n",
    "    are_equal2 = np.array_equal(model2_img, model_ori2)\n",
    "    are_equal3 = np.array_equal(model3_img, model_ori3)\n",
    "    are_equal4 = np.array_equal(model4_img, model_ori4)\n",
    "    if are_equal1 and are_equal2 and are_equal3 and are_equal4:\n",
    "        print(img_id, 'same')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626c6f6b-5ad5-4ca7-91bc-3c85cc9274fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
