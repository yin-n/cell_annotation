{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8d8cbe40-4b8a-4daa-9482-4f3a1be268ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "import napari\n",
    "import pandas as pd\n",
    "import zarr\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "import tiffile as tf\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f820e5d1-a6ab-4900-a97e-967646eceded",
   "metadata": {},
   "source": [
    "### Set load path and save path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a3b40fd2-9e1b-4561-a547-677757e2370b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created: ./crops/\n"
     ]
    }
   ],
   "source": [
    "##### change path\n",
    "# first path need to be first brain,second path need to be another brain\n",
    "fix_n5_path = ['/mnt/aperto/fused/fused.n5','/mnt/aperto/Tatz_brain_data/fused/fused.n5']\n",
    "\n",
    "# save path\n",
    "#create the directory if it does not exist\n",
    "##### change path\n",
    "# you need to change to the folder you want\n",
    "directory = './crops/'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    print(\"Directory created:\", directory)\n",
    "##### change path\n",
    "# you need to change to the folder you want\n",
    "save_path = directory\n",
    "##### change path\n",
    "#you need to change to the folder you want metadata path\n",
    "meta_path = './info.pkl'\n",
    "\n",
    "# create Zarr file object\n",
    "fix_zarr = [zarr.open(store=zarr.N5Store(fix_n5_path[0]), mode='r'), zarr.open(store=zarr.N5Store(fix_n5_path[1]), mode='r')]\n",
    "# if you use ngff ome.zarr\n",
    "# mov_zarr_path = '/mnt/ampa02_data01/tmurakami/240417_whole_4color_1st_M037-3pb/registration/round02.zarr'\n",
    "# mov_zarr = zarr.open(mov_zarr_path, mode='r')\n",
    "\n",
    "n5_setups = list(fix_zarr[0].keys())\n",
    "\n",
    "voxel_size = (2.0,1.3,1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c4e51507-0a99-4f5d-b8e5-03b3ba5f07bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your parameters here\n",
    "reference_chan = 3 # Integer or None\n",
    "segment_chan = 4\n",
    "\n",
    "# [100,256,256] crop size and FoV [100,768,768] are recommended for the 2D annotation\n",
    "crop_size = [100,256,256]\n",
    "FoV = [100,768,768]\n",
    "\n",
    "# set corner positions. I suggest finding the positions using BigDataViewer or relevant.\n",
    "# use the fourth column to add information\n",
    "center_positions = [\n",
    "    [1235,2510,775, 1],\n",
    "    [1325,3350,1542,2],\n",
    "    [1725,4632,1602]\n",
    "]\n",
    "\n",
    "corner_positions = [[(i-j//2) for i,j in zip(cent_pos, crop_size + [0])] for cent_pos in center_positions]\n",
    "\n",
    "# set True for 2D annotation and set False for 3D annotation\n",
    "select_plane = True\n",
    "\n",
    "# processing of parameters\n",
    "if not all([(j-i)>=0 for i,j in zip(crop_size, FoV)]):\n",
    "    raise ValueError('FoV should be larger than crop_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a62f4fe5-a1db-46b2-b4b0-0e5b635b3f5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make metadata file if it does not exist.\n",
    "if not os.path.exists(meta_path):\n",
    "    df = pd.DataFrame(columns=['ID', 'integer_ID', 'instance_counts', 'corner', 'source', 'ref_channel', 'channel', 'crop_size', 'isHard', 'plane_position','model_rank', 'comments'])\n",
    "else:\n",
    "    df = pd.read_pickle(meta_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "df5d8feb-f451-46b2-9ae8-7ddf4ddf664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have trouble like ImportError: cannot import name 'fastCopyAndTranspose' from 'numpy.core.multiarray' \n",
    "# try this\n",
    "#!pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a66934-f673-4588-a4a5-d598d537d58b",
   "metadata": {},
   "source": [
    "### Add 4 models prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5662909-c2f1-47e0-9fcd-40f74b3c091b",
   "metadata": {},
   "source": [
    "#### load original data and get the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "50dc0a2f-505c-491e-a347-e206e8efaee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287315/2941550060.py:2: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  ori_data = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "with open('./annotation_position_info.pkl', 'rb') as f:\n",
    "    ori_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9d2c85b8-422c-4d16-9a9b-053b483488e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all files in the directory ending with '_img.tif', and '_mask.tif' \n",
    "##### change path\n",
    "#you need to change this path to your image and mask file path\n",
    "img_dir = '/mnt/aperto/yin/cellpose_training/data/image_masks/' \n",
    "img_files = sorted(glob.glob(f'{img_dir}*_img.tif'))\n",
    "mask_files = sorted(glob.glob(f'{img_dir}*mask.tif'))\n",
    "img_id = [item.split('/')[-1][:4] for item in img_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "04a459ac-fe54-40c1-a441-cd40718f637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all the id are valid\n",
    "for item in img_id:\n",
    "    try:\n",
    "        ori_data.iloc[int(item)]\n",
    "    except:\n",
    "       print(item, 'invalid id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "684d5b4b-e0fb-414f-992b-da00b2565e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/mnt/ampa02_data01/tmurakami/240417_whole_4color_1st_M037-3pb/fused/fused.n5',\n",
       " '/mnt/ampa02_data01/tmurakami/240425_whole_4color_2nd_M037-3pb/fused/fused.n5'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optional run, check source of data\n",
    "set(ori_data['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "72d85dcb-89ac-4c08-8a81-0c55b00dda5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional run, check source of data\n",
    "source1 = []\n",
    "source2 = []\n",
    "for i in range(len(ori_data)):\n",
    "    if ori_data['source'][i].split('/')[-3] == '240417_whole_4color_1st_M037-3pb':\n",
    "        source1.append(i)\n",
    "    elif ori_data['source'][i].split('/')[-3] == '240425_whole_4color_2nd_M037-3pb':\n",
    "        source2.append(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be869a05-5992-4ef8-b8b8-4c194f4340f1",
   "metadata": {},
   "source": [
    "#### load cellpose prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6ccbe93a-02e1-4d15-93e2-519ccdd13758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to change path to your pkl path\n",
    "with open('./cellpose_nonorm_all.pkl', 'rb') as f:\n",
    "    cellpose_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3436ddae-cb8f-40fe-a2b7-8164eacba76d",
   "metadata": {},
   "source": [
    "#### load stardist results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d07f8add-0f48-49ec-a819-61264501d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./stardist_all.pkl', 'rb') as f:\n",
    "    stardist_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285b23dc-6a7a-4b54-ae42-25779f5c0c17",
   "metadata": {},
   "source": [
    "#### load swinUnetr results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c0cc2384-521c-4384-8204-07f823080cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./swin2d.pkl', 'rb') as f:\n",
    "    swin2d_predict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "682de1f9-76d9-4ddc-af6c-34761de01964",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./swin3d_win3.pkl', 'rb') as f:\n",
    "    swin_3D_pretrain_window3_predict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aa6e45-9813-4293-b7c9-8cf7ca10a917",
   "metadata": {},
   "source": [
    "#### load test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b2afefe9-47ef-4d3d-8104-21056bb7e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_file_path = './test_files.json'\n",
    "\n",
    "# read test json file\n",
    "with open(json_file_path) as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "# # filter norm test data\n",
    "test_files = [f for f in test_data if '*img.tif' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "89279043-2885-4a33-9259-fd1923db467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to recursively search for matching strings\n",
    "\n",
    "import json\n",
    "import fnmatch\n",
    "def find_matching_strings(obj, pattern):\n",
    "    matches = []\n",
    "    if isinstance(obj, dict):\n",
    "        for key, value in obj.items():\n",
    "            matches.extend(find_matching_strings(value, pattern))\n",
    "    elif isinstance(obj, list):\n",
    "        for item in obj:\n",
    "            matches.extend(find_matching_strings(item, pattern))\n",
    "    elif isinstance(obj, str):\n",
    "        if fnmatch.fnmatch(obj, pattern):\n",
    "            matches.append(obj)\n",
    "    return matches\n",
    "\n",
    "# Define the pattern to match\n",
    "pattern = '*img.tif'\n",
    "\n",
    "# Find all matching strings in the JSON data\n",
    "matching_strings = find_matching_strings(test_data, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "bb2bc7e1-7336-4c2b-8fef-0e28a8620a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = [item.split('_')[0] for item in matching_strings]\n",
    "test_id = sorted(test_id, key=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eed629a-8f16-4261-ab76-d4cb6c390b66",
   "metadata": {},
   "source": [
    "#### load shuffled list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "022a487a-9f0c-42e7-ad41-2238f9ae80b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./shuffle_model.pkl', 'rb') as f:\n",
    "    shuffle_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bd485ad1-798c-4bd5-9ccd-e3ffa514d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rank_list = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "640f3233-f4b8-4415-bb80-60a97f982e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### img_id\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0098154-a9e6-4aa9-bf4a-e184de3138dc",
   "metadata": {},
   "source": [
    "### Open napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e4d77651-9f40-4af1-8746-2f6471bfbec9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 0005 with the position [1227, 551, 2984]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to re-analyze the data? y or n y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing viewer...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Window' object has no attribute '_qt_window'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[168], line 197\u001b[0m\n\u001b[1;32m    194\u001b[0m viewer\u001b[38;5;241m.\u001b[39mcamera\u001b[38;5;241m.\u001b[39mzoom \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.5\u001b[39m\n\u001b[1;32m    196\u001b[0m viewer\u001b[38;5;241m.\u001b[39mdims\u001b[38;5;241m.\u001b[39mcurrent_step \u001b[38;5;241m=\u001b[39m (ori_plane,\u001b[38;5;241m400\u001b[39m,\u001b[38;5;241m400\u001b[39m)\n\u001b[0;32m--> 197\u001b[0m \u001b[43mviewer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m model_rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease type in the rank of model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    199\u001b[0m model_rank_list[ori_id]\u001b[38;5;241m=\u001b[39m model_rank\n",
      "File \u001b[0;32m~/miniconda3/envs/annotate/lib/python3.10/site-packages/napari/viewer.py:192\u001b[0m, in \u001b[0;36mViewer.show\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, block\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    191\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Resize, show, and raise the viewer window.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/annotate/lib/python3.10/site-packages/napari/_qt/qt_main_window.py:1472\u001b[0m, in \u001b[0;36mWindow.show\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1461\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1462\u001b[0m             trans\u001b[38;5;241m.\u001b[39m_(\n\u001b[1;32m   1463\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe window geometry settings could not be loaded due to the following error: \u001b[39m\u001b[38;5;132;01m{err}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1468\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1469\u001b[0m         )\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;66;03m# Resize axis labels now that window is shown\u001b[39;00m\n\u001b[0;32m-> 1472\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_qt_viewer\u001b[49m\u001b[38;5;241m.\u001b[39mdims\u001b[38;5;241m.\u001b[39m_resize_axis_labels()\n\u001b[1;32m   1474\u001b[0m \u001b[38;5;66;03m# We want to bring the viewer to the front when\u001b[39;00m\n\u001b[1;32m   1475\u001b[0m \u001b[38;5;66;03m# A) it is our own event loop OR we are running in jupyter\u001b[39;00m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;66;03m# B) it is not the first time a QMainWindow is being created\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[38;5;66;03m# _qt_window has been created.\u001b[39;00m\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;66;03m# See #721, #732, #735, #795, #1594\u001b[39;00m\n\u001b[1;32m   1482\u001b[0m app_name \u001b[38;5;241m=\u001b[39m QApplication\u001b[38;5;241m.\u001b[39minstance()\u001b[38;5;241m.\u001b[39mapplicationName()\n",
      "File \u001b[0;32m~/miniconda3/envs/annotate/lib/python3.10/site-packages/napari/_qt/qt_main_window.py:821\u001b[0m, in \u001b[0;36mWindow._qt_viewer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_qt_viewer\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# this is starting to be \"vestigial\"... this property could be removed\u001b[39;00m\n\u001b[0;32m--> 821\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_qt_window\u001b[49m\u001b[38;5;241m.\u001b[39m_qt_viewer\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Window' object has no attribute '_qt_window'"
     ]
    }
   ],
   "source": [
    "for ori_id in test_id:\n",
    "    ori_corner_position = [ori_data['corner'][int(ori_id)]]\n",
    "    ori_plane = int(ori_data['plane_position'][int(ori_id)])\n",
    "    segment_chan = int(ori_data['channel'][int(ori_id)])\n",
    "    reference_chan =  int(ori_data['ref_channel'][int(ori_id)])\n",
    "    #check which source it should be int 0 or 1\n",
    "    brain_source = int(ori_data['source'][int(ori_id)].split('/')[-3].split('_')[-2][0])-1\n",
    "    ##########\n",
    "    ## add cellpose prediction\n",
    "    try:\n",
    "        cellpose_predict = cellpose_data[ori_id]\n",
    "    except:\n",
    "        print(f'this id {ori_id} is exceed original id range, continue')\n",
    "        continue\n",
    "    model_id = shuffle_model[ori_id]\n",
    "    \n",
    "    # expand cellpose_prediction to correct size\n",
    "    # create a 256x256 array of zeros\n",
    "    single_layer = np.zeros((768, 768))\n",
    "    # stack this array 100 times along a new axis (axis=0)\n",
    "    data1 = np.stack([single_layer] * 100, axis=0)\n",
    "    expanded_array = np.zeros((768, 768))\n",
    "    # Calculate the starting indices to place the 256x256 array in the center\n",
    "    start_index = (768 - 256) // 2\n",
    "    # Place the 256x256 array in the center of the 768x768 array\n",
    "    expanded_array[start_index:start_index+256, start_index:start_index+256] = cellpose_predict\n",
    "    data1[ori_plane] = expanded_array\n",
    "    data1 = data1.astype(int)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # create a 256x256 array of zeros\n",
    "    single_layer = np.zeros((768, 768))\n",
    "    # stack this array 100 times along a new axis (axis=0)\n",
    "    data2 = np.stack([single_layer] * 100, axis=0)\n",
    "    expanded_array = np.zeros((768, 768))\n",
    "    # Calculate the starting indices to place the 256x256 array in the center\n",
    "    start_index = (768 - 256) // 2\n",
    "    # Place the 256x256 array in the center of the 768x768 array\n",
    "    expanded_array[start_index:start_index+256, start_index:start_index+256] = stardist_data[ori_id]\n",
    "    data2[ori_plane] = expanded_array\n",
    "    data2 = data2.astype(int)\n",
    "\n",
    "\n",
    "    # create a 256x256 array of zeros\n",
    "    single_layer = np.zeros((768, 768))\n",
    "    # stack this array 100 times along a new axis (axis=0)\n",
    "    data3 = np.stack([single_layer] * 100, axis=0)\n",
    "    expanded_array = np.zeros((768, 768))\n",
    "    # Calculate the starting indices to place the 256x256 array in the center\n",
    "    start_index = (768 - 256) // 2\n",
    "    # Place the 256x256 array in the center of the 768x768 array\n",
    "    expanded_array[start_index:start_index+256, start_index:start_index+256] = swin2d_predict[ori_id]\n",
    "    data3[ori_plane] = expanded_array\n",
    "    data3 = data3.astype(int)\n",
    "\n",
    "\n",
    "    # create a 256x256 array of zeros\n",
    "    single_layer = np.zeros((768, 768))\n",
    "    # stack this array 100 times along a new axis (axis=0)\n",
    "    data4 = np.stack([single_layer] * 100, axis=0)\n",
    "    expanded_array = np.zeros((768, 768))\n",
    "    # Calculate the starting indices to place the 256x256 array in the center\n",
    "    start_index = (768 - 256) // 2\n",
    "    # Place the 256x256 array in the center of the 768x768 array\n",
    "    expanded_array[start_index:start_index+256, start_index:start_index+256] = swin_3D_pretrain_window3_predict[ori_id]\n",
    "    data4[ori_plane] = expanded_array\n",
    "    data4 = data4.astype(int)\n",
    "\n",
    "    \n",
    "    data_map = {\n",
    "        1: data1,\n",
    "        2: data2,\n",
    "        3: data3,\n",
    "    }\n",
    "    \n",
    "    class1_data = data_map.get( model_id[0], data4)     \n",
    "    class2_data = data_map.get( model_id[1], data4)\n",
    "    class3_data = data_map.get( model_id[2], data4)     \n",
    "    class4_data = data_map.get( model_id[3], data4)     \n",
    "    \n",
    "    pos = ori_corner_position[0]\n",
    "    if len(pos) <= 2:\n",
    "        raise ValueError('The position should have length 3')\n",
    "    elif len(pos) == 3:\n",
    "        isHard = 0\n",
    "    elif len(pos) == 4:\n",
    "        isHard = pos[-1]\n",
    "        pos = pos[:-1]\n",
    "    else:\n",
    "        raise ValueError('You have a wrong position format')\n",
    "        \n",
    "    print(f\"The index {ori_id} with the position {pos}\")\n",
    "    idx = int(ori_id)\n",
    "    \n",
    "    # find out any duplication between the current data and the metadata\n",
    "    # if it is duplicated, ask \n",
    "    flag = False\n",
    "    if df['corner'].isin([pos]).any():\n",
    "        for k in df['integer_ID'][df['corner'].isin([pos])].to_list():\n",
    "            if ((df.loc[k,'source'] == fix_n5_path[brain_source]) and \n",
    "                (df.loc[k,'ref_channel'] == reference_chan) and \n",
    "                (df.loc[k,'channel'] == segment_chan) and \n",
    "                (df.loc[k,'crop_size'] == crop_size) and\n",
    "                (df.loc[k,'select_plane'] == select_plane)):\n",
    "                flag = True\n",
    "                idx = k\n",
    "    \n",
    "    if flag:\n",
    "        ans = input(\"Do you want to re-analyze the data? y or n\")\n",
    "        if ans != 'y':\n",
    "            continue\n",
    "        \n",
    "    # set file path to be saved for both image and mask\n",
    "    prefix = str(idx)\n",
    "    while len(prefix) < 4:\n",
    "        prefix = '0' + prefix\n",
    "    img_path = os.path.join(save_path, prefix+'_img.tif')\n",
    "    mask_path = [os.path.join(save_path, prefix+'_model1.tif')\n",
    "                ,os.path.join(save_path, prefix+'_model2.tif')\n",
    "                ,os.path.join(save_path, prefix+'_model3.tif')\n",
    "                ,os.path.join(save_path, prefix+'_model4.tif')]\n",
    "\n",
    "    #### get which sources\n",
    "\n",
    "    # get the image of a channel to be segmented\n",
    "    FoV_stack = []\n",
    "    img = fix_zarr[brain_source][n5_setups[segment_chan]]['timepoint0']['s0']\n",
    "\n",
    "    # set the corner of FoV in napari\n",
    "    top_corner = tuple(i-(k-j)//2 for i,j,k in zip(pos, crop_size, FoV))\n",
    "    bottom_corner = tuple(i+j+(k-j)//2 for i,j,k in zip(pos, crop_size, FoV))\n",
    "    top_corner = tuple(j if j>=i else i for i,j in zip([0,0,0],top_corner))\n",
    "    bottom_corner = tuple(j if j<=i else i for i,j in zip(img.shape,bottom_corner))\n",
    "    \n",
    "    # prepare to make border lines\n",
    "    top_border_corner = tuple((k-j)//2 for j,k in zip(crop_size, FoV))\n",
    "    bottom_border_corner = tuple(j+(k-j)//2 for j,k in zip(crop_size, FoV))\n",
    "    \n",
    "    FoV_segment = img[tuple(slice(i,j) for i,j in zip(top_corner, bottom_corner))]\n",
    "\n",
    "    # get the image of a reference of channel\n",
    "    if reference_chan is not None:\n",
    "        img = fix_zarr[brain_source][n5_setups[reference_chan]]['timepoint0']['s0']\n",
    "        FoV_reference = img[tuple(slice(i,j) for i,j in zip(top_corner, bottom_corner))]\n",
    "        FoV_stack.append(FoV_reference)\n",
    "    \n",
    "    FoV_stack.append(FoV_segment)\n",
    "    FoV_stack = np.stack(FoV_stack)\n",
    "\n",
    "    ##### FoV is a 2channel(reference and signal) Field of view\n",
    "    # open Napari. Pause for loop until close the window\n",
    "    viewer = napari.Viewer()\n",
    "    # set hotkey\n",
    "     # set quit key\n",
    "    @viewer.bind_key('q')\n",
    "    def close_viewer(viewer):\n",
    "        print(\"Closing viewer...\")\n",
    "        viewer.close()\n",
    "\n",
    "     #set hide hotkey\n",
    "    @viewer.bind_key('h')\n",
    "    def toggle_layer_visibility(viewer):\n",
    "        layer = viewer.layers.selection.active\n",
    "        if layer is not None:\n",
    "            layer.visible = not layer.visible\n",
    "    \n",
    "    viewer.add_image(FoV_stack, channel_axis=0, scale=voxel_size, contrast_limits=[0,65535])\n",
    "    viewer.add_shapes([[bottom_border_corner[1]*voxel_size[1],bottom_border_corner[2]*voxel_size[2]],[top_border_corner[1]*voxel_size[1],bottom_border_corner[2]*voxel_size[2]]],\n",
    "                      edge_width=2,edge_color='white',ndim=2,shape_type='line')\n",
    "    viewer.add_shapes([[top_border_corner[1]*voxel_size[1],bottom_border_corner[2]*voxel_size[2]],[top_border_corner[1]*voxel_size[1],top_border_corner[2]*voxel_size[2]]],\n",
    "                  edge_width=2,edge_color='white',ndim=2,shape_type='line')\n",
    "    viewer.add_shapes([[bottom_border_corner[1]*voxel_size[1],bottom_border_corner[2]*voxel_size[2]],[bottom_border_corner[1]*voxel_size[1],top_border_corner[2]*voxel_size[2]]],\n",
    "                  edge_width=2,edge_color='white',ndim=2,shape_type='line')\n",
    "    viewer.add_shapes([[bottom_border_corner[1]*voxel_size[1],top_border_corner[2]*voxel_size[2]],[top_border_corner[1]*voxel_size[1],top_border_corner[2]*voxel_size[2]]],\n",
    "                  edge_width=2,edge_color='white',ndim=2,shape_type='line')\n",
    "    \n",
    "    #labels = viewer.add_labels(np.zeros_like(FoV_segment), name='segmentation', scale=voxel_size)\n",
    "    #add three classes label layers\n",
    "    labels_class1 = viewer.add_labels(class1_data,  name=f'model1({ori_plane})', scale=voxel_size)\n",
    "    labels_class1.opacity = 1.0\n",
    "    labels_class1.brush_size = 1\n",
    "    labels_class2 = viewer.add_labels(class2_data,  name=f'model2({ori_plane})', scale=voxel_size)\n",
    "    labels_class2.opacity = 1.0\n",
    "    labels_class2.brush_size = 1\n",
    "    labels_class3 = viewer.add_labels(class3_data,  name=f'model3({ori_plane})', scale=voxel_size)\n",
    "    labels_class3.opacity = 1.0\n",
    "    labels_class3.brush_size = 1\n",
    "    labels_class4 = viewer.add_labels(class4_data,  name=f'model4({ori_plane})', scale=voxel_size)\n",
    "    labels_class4.opacity = 1.0\n",
    "    labels_class4.brush_size = 1\n",
    "    \n",
    "    viewer.camera.zoom = 1.5\n",
    "    \n",
    "    viewer.dims.current_step = (ori_plane,400,400)\n",
    "    viewer.show(block=True)\n",
    "    model_rank = input(\"Please type in the rank of model\")\n",
    "    model_rank_list[ori_id]= model_rank\n",
    "    comment = input(\"Do you have any comments when ranking the model?\")\n",
    "\n",
    "    \n",
    "    sub_area_slicer = tuple(slice(i,j) for i,j in zip(top_border_corner,bottom_border_corner))\n",
    "    ######\n",
    "    # subarea shape\n",
    "    # save images and segmentation.\n",
    "    img = np.swapaxes(FoV_stack[(slice(0,None),)+sub_area_slicer],0,1)\n",
    "    ######\n",
    "    # modify this to cellpose label\n",
    "    #labels_img = labels.data[sub_area_slicer]\n",
    "    labels_img_class1 = labels_class1.data[sub_area_slicer]\n",
    "    labels_img_class2 = labels_class2.data[sub_area_slicer]\n",
    "    labels_img_class3 = labels_class3.data[sub_area_slicer]\n",
    "    labels_img_class4 = labels_class4.data[sub_area_slicer]\n",
    "\n",
    "   \n",
    "    if select_plane:\n",
    "        print('selected and save')\n",
    "        ##########\n",
    "        # modify this to original label\n",
    "        plane_pos = np.argmax((labels_class1.data>0).sum(axis=(1,2)))\n",
    "        img = img[plane_pos,...]\n",
    "        labels_img_class1 = labels_img_class1[plane_pos,...]\n",
    "        labels_img_class2 = labels_img_class2[plane_pos,...]\n",
    "        labels_img_class3 = labels_img_class3[plane_pos,...]\n",
    "        labels_img_class4 = labels_img_class4[plane_pos,...]\n",
    "        \n",
    "        io.imsave(img_path, img, plugin='tifffile', imagej=True, metadata={'axes': 'CYX'})\n",
    "        io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
    "        io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
    "        io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
    "        io.imsave(mask_path[3], labels_img_class4, plugin='tifffile')\n",
    "\n",
    "    else:\n",
    "        print('#############')\n",
    "        print('not selected and save')\n",
    "        io.imsave(img_path, img, plugin='tifffile', imagej=True, metadata={'axes': 'ZCYX'})\n",
    "        io.imsave(mask_path[0], labels_img_class1, plugin='tifffile')\n",
    "        io.imsave(mask_path[1], labels_img_class2, plugin='tifffile')\n",
    "        io.imsave(mask_path[2], labels_img_class3, plugin='tifffile')\n",
    "    # update the metadata\n",
    "    df.loc[idx,'ID'] = prefix\n",
    "    df.loc[idx,'integer_ID'] = idx\n",
    "    count = (np.unique(labels_img_class1)).size - 1\n",
    "    df.loc[idx,'instance_counts'] = count\n",
    "    df.at[idx,'corner'] = pos\n",
    "    df.loc[idx, 'source'] = fix_n5_path[brain_source]\n",
    "    df.loc[idx, 'ref_channel'] = reference_chan\n",
    "    df.loc[idx, 'channel'] = segment_chan\n",
    "    df.at[idx, 'crop_size'] = crop_size\n",
    "    df.loc[idx, 'select_plane'] = select_plane\n",
    "    df.loc[idx, 'isHard'] = isHard\n",
    "    df.loc[idx, 'model_rank'] = model_rank\n",
    "    df.loc[idx, 'comments'] = comment\n",
    "    \n",
    "    if select_plane:\n",
    "        df.loc[idx, 'plane_position'] = int(plane_pos)\n",
    "    else:\n",
    "        df.loc[idx, 'plane_position'] = -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e2e995-581e-431b-9f90-4acdad54f534",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4ff5b42e-e22b-496d-8eb0-9d3109480c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the file through pickle the metadata\n",
    "df.to_pickle(meta_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff714c7b-281c-4837-bf25-0c7980c2c9f1",
   "metadata": {},
   "source": [
    "#### set begining id for next round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ff329081-757d-4f92-a015-166f47cb9601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current image id 37, next begin id 37\n"
     ]
    }
   ],
   "source": [
    "# if you don't want to run all again, set the beginning id as begin\n",
    "curent_id = test_id.index(ori_id)\n",
    "begin_id = curent_id\n",
    "print(f'current image id {curent_id}, next begin id {begin_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d3d4bdb5-da67-404a-9dc1-db072ef554b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional)if you want to start all over again, reset begin_id as 0\n",
    "# begin_id = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
